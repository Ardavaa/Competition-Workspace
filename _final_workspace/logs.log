2024-09-06 22:52:09,519:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-06 22:52:09,519:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-06 22:52:09,519:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-06 22:52:09,519:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-09-06 22:52:10,145:INFO:PyCaret ClassificationExperiment
2024-09-06 22:52:10,145:INFO:Logging name: clf-default-name
2024-09-06 22:52:10,145:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-09-06 22:52:10,145:INFO:version 3.3.2
2024-09-06 22:52:10,145:INFO:Initializing setup()
2024-09-06 22:52:10,145:INFO:self.USI: 098d
2024-09-06 22:52:10,145:INFO:self._variable_keys: {'idx', 'y', 'y_train', 'seed', 'USI', 'memory', 'fix_imbalance', 'exp_id', 'exp_name_log', 'data', 'is_multiclass', '_available_plots', 'html_param', 'X_train', 'log_plots_param', 'fold_generator', 'X_test', 'y_test', 'n_jobs_param', 'X', 'gpu_param', 'pipeline', 'fold_groups_param', 'fold_shuffle_param', '_ml_usecase', 'target_param', 'gpu_n_jobs_param', 'logging_param'}
2024-09-06 22:52:10,145:INFO:Checking environment
2024-09-06 22:52:10,145:INFO:python_version: 3.11.9
2024-09-06 22:52:10,145:INFO:python_build: ('main', 'Apr 19 2024 16:40:41')
2024-09-06 22:52:10,145:INFO:machine: AMD64
2024-09-06 22:52:10,146:INFO:platform: Windows-10-10.0.22631-SP0
2024-09-06 22:52:10,152:INFO:Memory: svmem(total=16867028992, available=3946987520, percent=76.6, used=12920041472, free=3946987520)
2024-09-06 22:52:10,153:INFO:Physical Core: 6
2024-09-06 22:52:10,153:INFO:Logical Core: 12
2024-09-06 22:52:10,153:INFO:Checking libraries
2024-09-06 22:52:10,153:INFO:System:
2024-09-06 22:52:10,153:INFO:    python: 3.11.9 | packaged by Anaconda, Inc. | (main, Apr 19 2024, 16:40:41) [MSC v.1916 64 bit (AMD64)]
2024-09-06 22:52:10,153:INFO:executable: c:\Users\ardav\miniconda3\envs\vsc\python.exe
2024-09-06 22:52:10,153:INFO:   machine: Windows-10-10.0.22631-SP0
2024-09-06 22:52:10,153:INFO:PyCaret required dependencies:
2024-09-06 22:52:10,156:INFO:                 pip: 23.2.1
2024-09-06 22:52:10,156:INFO:          setuptools: 67.8.0
2024-09-06 22:52:10,156:INFO:             pycaret: 3.3.2
2024-09-06 22:52:10,156:INFO:             IPython: 8.14.0
2024-09-06 22:52:10,156:INFO:          ipywidgets: 8.1.5
2024-09-06 22:52:10,156:INFO:                tqdm: 4.66.5
2024-09-06 22:52:10,156:INFO:               numpy: 1.26.4
2024-09-06 22:52:10,156:INFO:              pandas: 2.0.3
2024-09-06 22:52:10,156:INFO:              jinja2: 3.1.4
2024-09-06 22:52:10,156:INFO:               scipy: 1.10.1
2024-09-06 22:52:10,156:INFO:              joblib: 1.2.0
2024-09-06 22:52:10,156:INFO:             sklearn: 1.4.2
2024-09-06 22:52:10,156:INFO:                pyod: 2.0.1
2024-09-06 22:52:10,156:INFO:            imblearn: 0.12.3
2024-09-06 22:52:10,156:INFO:   category_encoders: 2.6.3
2024-09-06 22:52:10,156:INFO:            lightgbm: 4.5.0
2024-09-06 22:52:10,156:INFO:               numba: 0.60.0
2024-09-06 22:52:10,156:INFO:            requests: 2.32.3
2024-09-06 22:52:10,156:INFO:          matplotlib: 3.7.1
2024-09-06 22:52:10,156:INFO:          scikitplot: 0.3.7
2024-09-06 22:52:10,156:INFO:         yellowbrick: 1.5
2024-09-06 22:52:10,157:INFO:              plotly: 5.16.1
2024-09-06 22:52:10,157:INFO:    plotly-resampler: Not installed
2024-09-06 22:52:10,157:INFO:             kaleido: 0.2.1
2024-09-06 22:52:10,157:INFO:           schemdraw: 0.15
2024-09-06 22:52:10,157:INFO:         statsmodels: 0.14.2
2024-09-06 22:52:10,157:INFO:              sktime: 0.26.0
2024-09-06 22:52:10,157:INFO:               tbats: 1.1.3
2024-09-06 22:52:10,157:INFO:            pmdarima: 2.0.4
2024-09-06 22:52:10,157:INFO:              psutil: 5.9.0
2024-09-06 22:52:10,157:INFO:          markupsafe: 2.1.3
2024-09-06 22:52:10,157:INFO:             pickle5: Not installed
2024-09-06 22:52:10,157:INFO:         cloudpickle: 3.0.0
2024-09-06 22:52:10,157:INFO:         deprecation: 2.1.0
2024-09-06 22:52:10,157:INFO:              xxhash: 3.5.0
2024-09-06 22:52:10,157:INFO:           wurlitzer: Not installed
2024-09-06 22:52:10,157:INFO:PyCaret optional dependencies:
2024-09-06 22:52:15,184:INFO:                shap: Not installed
2024-09-06 22:52:15,184:INFO:           interpret: Not installed
2024-09-06 22:52:15,184:INFO:                umap: Not installed
2024-09-06 22:52:15,185:INFO:     ydata_profiling: Not installed
2024-09-06 22:52:15,185:INFO:  explainerdashboard: Not installed
2024-09-06 22:52:15,185:INFO:             autoviz: Not installed
2024-09-06 22:52:15,185:INFO:           fairlearn: Not installed
2024-09-06 22:52:15,185:INFO:          deepchecks: Not installed
2024-09-06 22:52:15,185:INFO:             xgboost: 2.1.1
2024-09-06 22:52:15,185:INFO:            catboost: 1.2.5
2024-09-06 22:52:15,185:INFO:              kmodes: Not installed
2024-09-06 22:52:15,185:INFO:             mlxtend: Not installed
2024-09-06 22:52:15,185:INFO:       statsforecast: Not installed
2024-09-06 22:52:15,185:INFO:        tune_sklearn: Not installed
2024-09-06 22:52:15,185:INFO:                 ray: Not installed
2024-09-06 22:52:15,185:INFO:            hyperopt: Not installed
2024-09-06 22:52:15,185:INFO:              optuna: 4.0.0
2024-09-06 22:52:15,185:INFO:               skopt: Not installed
2024-09-06 22:52:15,185:INFO:              mlflow: Not installed
2024-09-06 22:52:15,185:INFO:              gradio: 4.41.0
2024-09-06 22:52:15,185:INFO:             fastapi: 0.112.1
2024-09-06 22:52:15,185:INFO:             uvicorn: 0.30.6
2024-09-06 22:52:15,185:INFO:              m2cgen: Not installed
2024-09-06 22:52:15,185:INFO:           evidently: Not installed
2024-09-06 22:52:15,185:INFO:               fugue: Not installed
2024-09-06 22:52:15,185:INFO:           streamlit: 1.38.0
2024-09-06 22:52:15,185:INFO:             prophet: Not installed
2024-09-06 22:52:15,185:INFO:None
2024-09-06 22:52:15,185:INFO:Set up data.
2024-09-06 22:52:15,197:INFO:Set up folding strategy.
2024-09-06 22:52:15,197:INFO:Set up train/test split.
2024-09-06 22:52:15,215:INFO:Set up index.
2024-09-06 22:52:15,217:INFO:Assigning column types.
2024-09-06 22:52:15,227:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-09-06 22:52:15,267:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-09-06 22:52:15,271:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-09-06 22:52:15,312:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-06 22:52:15,315:INFO:Soft dependency imported: catboost: 1.2.5
2024-09-06 22:52:15,378:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-09-06 22:52:15,379:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-09-06 22:52:15,416:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-06 22:52:15,420:INFO:Soft dependency imported: catboost: 1.2.5
2024-09-06 22:52:15,421:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-09-06 22:52:15,472:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-09-06 22:52:15,502:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-06 22:52:15,504:INFO:Soft dependency imported: catboost: 1.2.5
2024-09-06 22:52:15,553:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-09-06 22:52:15,580:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-06 22:52:15,583:INFO:Soft dependency imported: catboost: 1.2.5
2024-09-06 22:52:15,584:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-09-06 22:52:15,655:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-06 22:52:15,658:INFO:Soft dependency imported: catboost: 1.2.5
2024-09-06 22:52:15,726:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-06 22:52:15,729:INFO:Soft dependency imported: catboost: 1.2.5
2024-09-06 22:52:15,731:INFO:Preparing preprocessing pipeline...
2024-09-06 22:52:15,733:INFO:Set up simple imputation.
2024-09-06 22:52:15,734:INFO:Set up column name cleaning.
2024-09-06 22:52:15,801:INFO:Finished creating preprocessing pipeline.
2024-09-06 22:52:15,807:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\ardav\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Tahun Kelahiran',
                                             'Kelas Pekerjaan', 'fnlwgt',
                                             'Pendidikan', 'Jenjang Pendidikan',
                                             'Status', 'Pekerjaan', 'Hubungan',
                                             'Etnis', 'sex', 'pendapatan',
                                             'pengeluaran', 'hours per week',
                                             'Asal Negara', 'jumlah_anak'],
                                    transformer...
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2024-09-06 22:52:15,807:INFO:Creating final display dataframe.
2024-09-06 22:52:15,967:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target            income
2                   Target type            Binary
3           Original data shape       (26035, 16)
4        Transformed data shape       (26035, 16)
5   Transformed train set shape       (18224, 16)
6    Transformed test set shape        (7811, 16)
7              Numeric features                15
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              098d
2024-09-06 22:52:16,067:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-06 22:52:16,070:INFO:Soft dependency imported: catboost: 1.2.5
2024-09-06 22:52:16,195:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-06 22:52:16,200:INFO:Soft dependency imported: catboost: 1.2.5
2024-09-06 22:52:16,202:INFO:setup() successfully completed in 6.06s...............
2024-09-06 22:52:16,202:INFO:Initializing compare_models()
2024-09-06 22:52:16,202:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000288CF65A290>, include=None, exclude=None, fold=5, round=4, cross_validation=True, sort=F1, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x00000288CF65A290>, 'include': None, 'exclude': None, 'fold': 5, 'round': 4, 'cross_validation': True, 'sort': 'F1', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2024-09-06 22:52:16,202:INFO:Checking exceptions
2024-09-06 22:52:16,216:INFO:Preparing display monitor
2024-09-06 22:52:16,252:INFO:Initializing Logistic Regression
2024-09-06 22:52:16,252:INFO:Total runtime is 8.598963419596355e-06 minutes
2024-09-06 22:52:16,258:INFO:SubProcess create_model() called ==================================
2024-09-06 22:52:16,259:INFO:Initializing create_model()
2024-09-06 22:52:16,259:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000288CF65A290>, estimator=lr, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000288D1C19F90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-06 22:52:16,259:INFO:Checking exceptions
2024-09-06 22:52:16,260:INFO:Importing libraries
2024-09-06 22:52:16,260:INFO:Copying training dataset
2024-09-06 22:52:16,288:INFO:Defining folds
2024-09-06 22:52:16,288:INFO:Declaring metric variables
2024-09-06 22:52:16,293:INFO:Importing untrained model
2024-09-06 22:52:16,298:INFO:Logistic Regression Imported successfully
2024-09-06 22:52:16,309:INFO:Starting cross validation
2024-09-06 22:52:16,311:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-09-06 22:52:25,593:WARNING:c:\Users\ardav\miniconda3\envs\vsc\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-09-06 22:52:25,621:WARNING:c:\Users\ardav\miniconda3\envs\vsc\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-09-06 22:52:25,633:WARNING:c:\Users\ardav\miniconda3\envs\vsc\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-09-06 22:52:25,644:WARNING:c:\Users\ardav\miniconda3\envs\vsc\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-09-06 22:52:25,647:WARNING:c:\Users\ardav\miniconda3\envs\vsc\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-09-06 22:52:25,712:INFO:Calculating mean and std
2024-09-06 22:52:25,715:INFO:Creating metrics dataframe
2024-09-06 22:52:25,722:INFO:Uploading results into container
2024-09-06 22:52:25,723:INFO:Uploading model into container now
2024-09-06 22:52:25,725:INFO:_master_model_container: 1
2024-09-06 22:52:25,725:INFO:_display_container: 2
2024-09-06 22:52:25,726:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-09-06 22:52:25,727:INFO:create_model() successfully completed......................................
2024-09-06 22:52:25,938:INFO:SubProcess create_model() end ==================================
2024-09-06 22:52:25,939:INFO:Creating metrics dataframe
2024-09-06 22:52:25,949:INFO:Initializing K Neighbors Classifier
2024-09-06 22:52:25,949:INFO:Total runtime is 0.16163036425908406 minutes
2024-09-06 22:52:25,955:INFO:SubProcess create_model() called ==================================
2024-09-06 22:52:25,955:INFO:Initializing create_model()
2024-09-06 22:52:25,956:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000288CF65A290>, estimator=knn, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000288D1C19F90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-06 22:52:25,956:INFO:Checking exceptions
2024-09-06 22:52:25,956:INFO:Importing libraries
2024-09-06 22:52:25,956:INFO:Copying training dataset
2024-09-06 22:52:25,980:INFO:Defining folds
2024-09-06 22:52:25,981:INFO:Declaring metric variables
2024-09-06 22:52:25,987:INFO:Importing untrained model
2024-09-06 22:52:25,993:INFO:K Neighbors Classifier Imported successfully
2024-09-06 22:52:26,005:INFO:Starting cross validation
2024-09-06 22:52:26,006:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-09-06 22:52:30,656:INFO:Calculating mean and std
2024-09-06 22:52:30,659:INFO:Creating metrics dataframe
2024-09-06 22:52:30,661:INFO:Uploading results into container
2024-09-06 22:52:30,662:INFO:Uploading model into container now
2024-09-06 22:52:30,663:INFO:_master_model_container: 2
2024-09-06 22:52:30,663:INFO:_display_container: 2
2024-09-06 22:52:30,664:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-09-06 22:52:30,664:INFO:create_model() successfully completed......................................
2024-09-06 22:52:30,812:INFO:SubProcess create_model() end ==================================
2024-09-06 22:52:30,812:INFO:Creating metrics dataframe
2024-09-06 22:52:30,821:INFO:Initializing Naive Bayes
2024-09-06 22:52:30,821:INFO:Total runtime is 0.24282917579015095 minutes
2024-09-06 22:52:30,825:INFO:SubProcess create_model() called ==================================
2024-09-06 22:52:30,825:INFO:Initializing create_model()
2024-09-06 22:52:30,825:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000288CF65A290>, estimator=nb, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000288D1C19F90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-06 22:52:30,825:INFO:Checking exceptions
2024-09-06 22:52:30,825:INFO:Importing libraries
2024-09-06 22:52:30,825:INFO:Copying training dataset
2024-09-06 22:52:30,842:INFO:Defining folds
2024-09-06 22:52:30,843:INFO:Declaring metric variables
2024-09-06 22:52:30,847:INFO:Importing untrained model
2024-09-06 22:52:30,852:INFO:Naive Bayes Imported successfully
2024-09-06 22:52:30,861:INFO:Starting cross validation
2024-09-06 22:52:30,862:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-09-06 22:52:33,854:INFO:Calculating mean and std
2024-09-06 22:52:33,856:INFO:Creating metrics dataframe
2024-09-06 22:52:33,858:INFO:Uploading results into container
2024-09-06 22:52:33,859:INFO:Uploading model into container now
2024-09-06 22:52:33,859:INFO:_master_model_container: 3
2024-09-06 22:52:33,860:INFO:_display_container: 2
2024-09-06 22:52:33,860:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-09-06 22:52:33,860:INFO:create_model() successfully completed......................................
2024-09-06 22:52:34,001:INFO:SubProcess create_model() end ==================================
2024-09-06 22:52:34,001:INFO:Creating metrics dataframe
2024-09-06 22:52:34,014:INFO:Initializing Decision Tree Classifier
2024-09-06 22:52:34,014:INFO:Total runtime is 0.29603463411331177 minutes
2024-09-06 22:52:34,018:INFO:SubProcess create_model() called ==================================
2024-09-06 22:52:34,024:INFO:Initializing create_model()
2024-09-06 22:52:34,024:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000288CF65A290>, estimator=dt, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000288D1C19F90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-06 22:52:34,024:INFO:Checking exceptions
2024-09-06 22:52:34,024:INFO:Importing libraries
2024-09-06 22:52:34,025:INFO:Copying training dataset
2024-09-06 22:52:34,053:INFO:Defining folds
2024-09-06 22:52:34,053:INFO:Declaring metric variables
2024-09-06 22:52:34,059:INFO:Importing untrained model
2024-09-06 22:52:34,063:INFO:Decision Tree Classifier Imported successfully
2024-09-06 22:52:34,072:INFO:Starting cross validation
2024-09-06 22:52:34,073:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-09-06 22:52:34,261:INFO:Calculating mean and std
2024-09-06 22:52:34,262:INFO:Creating metrics dataframe
2024-09-06 22:52:34,264:INFO:Uploading results into container
2024-09-06 22:52:34,265:INFO:Uploading model into container now
2024-09-06 22:52:34,265:INFO:_master_model_container: 4
2024-09-06 22:52:34,266:INFO:_display_container: 2
2024-09-06 22:52:34,266:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2024-09-06 22:52:34,266:INFO:create_model() successfully completed......................................
2024-09-06 22:52:34,398:INFO:SubProcess create_model() end ==================================
2024-09-06 22:52:34,399:INFO:Creating metrics dataframe
2024-09-06 22:52:34,407:INFO:Initializing SVM - Linear Kernel
2024-09-06 22:52:34,407:INFO:Total runtime is 0.30258793433507286 minutes
2024-09-06 22:52:34,410:INFO:SubProcess create_model() called ==================================
2024-09-06 22:52:34,411:INFO:Initializing create_model()
2024-09-06 22:52:34,411:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000288CF65A290>, estimator=svm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000288D1C19F90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-06 22:52:34,411:INFO:Checking exceptions
2024-09-06 22:52:34,411:INFO:Importing libraries
2024-09-06 22:52:34,411:INFO:Copying training dataset
2024-09-06 22:52:34,426:INFO:Defining folds
2024-09-06 22:52:34,426:INFO:Declaring metric variables
2024-09-06 22:52:34,430:INFO:Importing untrained model
2024-09-06 22:52:34,435:INFO:SVM - Linear Kernel Imported successfully
2024-09-06 22:52:34,444:INFO:Starting cross validation
2024-09-06 22:52:34,445:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-09-06 22:52:35,017:INFO:Calculating mean and std
2024-09-06 22:52:35,019:INFO:Creating metrics dataframe
2024-09-06 22:52:35,022:INFO:Uploading results into container
2024-09-06 22:52:35,023:INFO:Uploading model into container now
2024-09-06 22:52:35,024:INFO:_master_model_container: 5
2024-09-06 22:52:35,024:INFO:_display_container: 2
2024-09-06 22:52:35,024:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-09-06 22:52:35,024:INFO:create_model() successfully completed......................................
2024-09-06 22:52:35,154:INFO:SubProcess create_model() end ==================================
2024-09-06 22:52:35,155:INFO:Creating metrics dataframe
2024-09-06 22:52:35,164:INFO:Initializing Ridge Classifier
2024-09-06 22:52:35,164:INFO:Total runtime is 0.31520804166793825 minutes
2024-09-06 22:52:35,167:INFO:SubProcess create_model() called ==================================
2024-09-06 22:52:35,168:INFO:Initializing create_model()
2024-09-06 22:52:35,168:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000288CF65A290>, estimator=ridge, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000288D1C19F90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-06 22:52:35,168:INFO:Checking exceptions
2024-09-06 22:52:35,168:INFO:Importing libraries
2024-09-06 22:52:35,168:INFO:Copying training dataset
2024-09-06 22:52:35,186:INFO:Defining folds
2024-09-06 22:52:35,186:INFO:Declaring metric variables
2024-09-06 22:52:35,190:INFO:Importing untrained model
2024-09-06 22:52:35,196:INFO:Ridge Classifier Imported successfully
2024-09-06 22:52:35,202:INFO:Starting cross validation
2024-09-06 22:52:35,203:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-09-06 22:52:35,325:INFO:Calculating mean and std
2024-09-06 22:52:35,326:INFO:Creating metrics dataframe
2024-09-06 22:52:35,328:INFO:Uploading results into container
2024-09-06 22:52:35,329:INFO:Uploading model into container now
2024-09-06 22:52:35,329:INFO:_master_model_container: 6
2024-09-06 22:52:35,329:INFO:_display_container: 2
2024-09-06 22:52:35,330:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2024-09-06 22:52:35,330:INFO:create_model() successfully completed......................................
2024-09-06 22:52:35,461:INFO:SubProcess create_model() end ==================================
2024-09-06 22:52:35,461:INFO:Creating metrics dataframe
2024-09-06 22:52:35,472:INFO:Initializing Random Forest Classifier
2024-09-06 22:52:35,472:INFO:Total runtime is 0.3203435897827149 minutes
2024-09-06 22:52:35,475:INFO:SubProcess create_model() called ==================================
2024-09-06 22:52:35,475:INFO:Initializing create_model()
2024-09-06 22:52:35,475:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000288CF65A290>, estimator=rf, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000288D1C19F90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-06 22:52:35,475:INFO:Checking exceptions
2024-09-06 22:52:35,475:INFO:Importing libraries
2024-09-06 22:52:35,476:INFO:Copying training dataset
2024-09-06 22:52:35,491:INFO:Defining folds
2024-09-06 22:52:35,492:INFO:Declaring metric variables
2024-09-06 22:52:35,496:INFO:Importing untrained model
2024-09-06 22:52:35,500:INFO:Random Forest Classifier Imported successfully
2024-09-06 22:52:35,507:INFO:Starting cross validation
2024-09-06 22:52:35,508:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-09-06 22:52:37,036:INFO:Calculating mean and std
2024-09-06 22:52:37,039:INFO:Creating metrics dataframe
2024-09-06 22:52:37,042:INFO:Uploading results into container
2024-09-06 22:52:37,043:INFO:Uploading model into container now
2024-09-06 22:52:37,044:INFO:_master_model_container: 7
2024-09-06 22:52:37,045:INFO:_display_container: 2
2024-09-06 22:52:37,045:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2024-09-06 22:52:37,046:INFO:create_model() successfully completed......................................
2024-09-06 22:52:37,253:INFO:SubProcess create_model() end ==================================
2024-09-06 22:52:37,254:INFO:Creating metrics dataframe
2024-09-06 22:52:37,269:INFO:Initializing Quadratic Discriminant Analysis
2024-09-06 22:52:37,269:INFO:Total runtime is 0.350291387240092 minutes
2024-09-06 22:52:37,275:INFO:SubProcess create_model() called ==================================
2024-09-06 22:52:37,275:INFO:Initializing create_model()
2024-09-06 22:52:37,275:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000288CF65A290>, estimator=qda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000288D1C19F90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-06 22:52:37,275:INFO:Checking exceptions
2024-09-06 22:52:37,275:INFO:Importing libraries
2024-09-06 22:52:37,276:INFO:Copying training dataset
2024-09-06 22:52:37,297:INFO:Defining folds
2024-09-06 22:52:37,297:INFO:Declaring metric variables
2024-09-06 22:52:37,304:INFO:Importing untrained model
2024-09-06 22:52:37,310:INFO:Quadratic Discriminant Analysis Imported successfully
2024-09-06 22:52:37,321:INFO:Starting cross validation
2024-09-06 22:52:37,323:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-09-06 22:52:37,448:INFO:Calculating mean and std
2024-09-06 22:52:37,449:INFO:Creating metrics dataframe
2024-09-06 22:52:37,452:INFO:Uploading results into container
2024-09-06 22:52:37,453:INFO:Uploading model into container now
2024-09-06 22:52:37,454:INFO:_master_model_container: 8
2024-09-06 22:52:37,454:INFO:_display_container: 2
2024-09-06 22:52:37,454:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-09-06 22:52:37,454:INFO:create_model() successfully completed......................................
2024-09-06 22:52:37,600:INFO:SubProcess create_model() end ==================================
2024-09-06 22:52:37,600:INFO:Creating metrics dataframe
2024-09-06 22:52:37,610:INFO:Initializing Ada Boost Classifier
2024-09-06 22:52:37,610:INFO:Total runtime is 0.3559748530387879 minutes
2024-09-06 22:52:37,614:INFO:SubProcess create_model() called ==================================
2024-09-06 22:52:37,615:INFO:Initializing create_model()
2024-09-06 22:52:37,615:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000288CF65A290>, estimator=ada, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000288D1C19F90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-06 22:52:37,615:INFO:Checking exceptions
2024-09-06 22:52:37,615:INFO:Importing libraries
2024-09-06 22:52:37,615:INFO:Copying training dataset
2024-09-06 22:52:37,634:INFO:Defining folds
2024-09-06 22:52:37,634:INFO:Declaring metric variables
2024-09-06 22:52:37,638:INFO:Importing untrained model
2024-09-06 22:52:37,643:INFO:Ada Boost Classifier Imported successfully
2024-09-06 22:52:37,653:INFO:Starting cross validation
2024-09-06 22:52:37,655:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-09-06 22:52:37,710:WARNING:c:\Users\ardav\miniconda3\envs\vsc\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-06 22:52:37,711:WARNING:c:\Users\ardav\miniconda3\envs\vsc\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-06 22:52:37,719:WARNING:c:\Users\ardav\miniconda3\envs\vsc\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-06 22:52:37,721:WARNING:c:\Users\ardav\miniconda3\envs\vsc\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-06 22:52:37,727:WARNING:c:\Users\ardav\miniconda3\envs\vsc\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-06 22:52:38,487:INFO:Calculating mean and std
2024-09-06 22:52:38,489:INFO:Creating metrics dataframe
2024-09-06 22:52:38,490:INFO:Uploading results into container
2024-09-06 22:52:38,491:INFO:Uploading model into container now
2024-09-06 22:52:38,492:INFO:_master_model_container: 9
2024-09-06 22:52:38,492:INFO:_display_container: 2
2024-09-06 22:52:38,492:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2024-09-06 22:52:38,493:INFO:create_model() successfully completed......................................
2024-09-06 22:52:38,627:INFO:SubProcess create_model() end ==================================
2024-09-06 22:52:38,627:INFO:Creating metrics dataframe
2024-09-06 22:52:38,637:INFO:Initializing Gradient Boosting Classifier
2024-09-06 22:52:38,637:INFO:Total runtime is 0.3730853080749512 minutes
2024-09-06 22:52:38,640:INFO:SubProcess create_model() called ==================================
2024-09-06 22:52:38,641:INFO:Initializing create_model()
2024-09-06 22:52:38,641:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000288CF65A290>, estimator=gbc, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000288D1C19F90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-06 22:52:38,641:INFO:Checking exceptions
2024-09-06 22:52:38,642:INFO:Importing libraries
2024-09-06 22:52:38,642:INFO:Copying training dataset
2024-09-06 22:52:38,657:INFO:Defining folds
2024-09-06 22:52:38,657:INFO:Declaring metric variables
2024-09-06 22:52:38,661:INFO:Importing untrained model
2024-09-06 22:52:38,666:INFO:Gradient Boosting Classifier Imported successfully
2024-09-06 22:52:38,672:INFO:Starting cross validation
2024-09-06 22:52:38,673:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-09-06 22:52:41,087:INFO:Calculating mean and std
2024-09-06 22:52:41,089:INFO:Creating metrics dataframe
2024-09-06 22:52:41,091:INFO:Uploading results into container
2024-09-06 22:52:41,093:INFO:Uploading model into container now
2024-09-06 22:52:41,093:INFO:_master_model_container: 10
2024-09-06 22:52:41,093:INFO:_display_container: 2
2024-09-06 22:52:41,094:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-09-06 22:52:41,094:INFO:create_model() successfully completed......................................
2024-09-06 22:52:41,233:INFO:SubProcess create_model() end ==================================
2024-09-06 22:52:41,233:INFO:Creating metrics dataframe
2024-09-06 22:52:41,245:INFO:Initializing Linear Discriminant Analysis
2024-09-06 22:52:41,245:INFO:Total runtime is 0.4165627916653951 minutes
2024-09-06 22:52:41,250:INFO:SubProcess create_model() called ==================================
2024-09-06 22:52:41,250:INFO:Initializing create_model()
2024-09-06 22:52:41,251:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000288CF65A290>, estimator=lda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000288D1C19F90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-06 22:52:41,251:INFO:Checking exceptions
2024-09-06 22:52:41,251:INFO:Importing libraries
2024-09-06 22:52:41,251:INFO:Copying training dataset
2024-09-06 22:52:41,272:INFO:Defining folds
2024-09-06 22:52:41,273:INFO:Declaring metric variables
2024-09-06 22:52:41,276:INFO:Importing untrained model
2024-09-06 22:52:41,281:INFO:Linear Discriminant Analysis Imported successfully
2024-09-06 22:52:41,293:INFO:Starting cross validation
2024-09-06 22:52:41,294:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-09-06 22:52:41,467:INFO:Calculating mean and std
2024-09-06 22:52:41,469:INFO:Creating metrics dataframe
2024-09-06 22:52:41,471:INFO:Uploading results into container
2024-09-06 22:52:41,471:INFO:Uploading model into container now
2024-09-06 22:52:41,472:INFO:_master_model_container: 11
2024-09-06 22:52:41,472:INFO:_display_container: 2
2024-09-06 22:52:41,473:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-09-06 22:52:41,473:INFO:create_model() successfully completed......................................
2024-09-06 22:52:41,610:INFO:SubProcess create_model() end ==================================
2024-09-06 22:52:41,610:INFO:Creating metrics dataframe
2024-09-06 22:52:41,621:INFO:Initializing Extra Trees Classifier
2024-09-06 22:52:41,621:INFO:Total runtime is 0.42282767295837403 minutes
2024-09-06 22:52:41,626:INFO:SubProcess create_model() called ==================================
2024-09-06 22:52:41,626:INFO:Initializing create_model()
2024-09-06 22:52:41,626:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000288CF65A290>, estimator=et, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000288D1C19F90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-06 22:52:41,626:INFO:Checking exceptions
2024-09-06 22:52:41,626:INFO:Importing libraries
2024-09-06 22:52:41,626:INFO:Copying training dataset
2024-09-06 22:52:41,642:INFO:Defining folds
2024-09-06 22:52:41,642:INFO:Declaring metric variables
2024-09-06 22:52:41,646:INFO:Importing untrained model
2024-09-06 22:52:41,650:INFO:Extra Trees Classifier Imported successfully
2024-09-06 22:52:41,660:INFO:Starting cross validation
2024-09-06 22:52:41,661:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-09-06 22:52:43,132:INFO:Calculating mean and std
2024-09-06 22:52:43,134:INFO:Creating metrics dataframe
2024-09-06 22:52:43,137:INFO:Uploading results into container
2024-09-06 22:52:43,138:INFO:Uploading model into container now
2024-09-06 22:52:43,139:INFO:_master_model_container: 12
2024-09-06 22:52:43,139:INFO:_display_container: 2
2024-09-06 22:52:43,139:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2024-09-06 22:52:43,139:INFO:create_model() successfully completed......................................
2024-09-06 22:52:43,281:INFO:SubProcess create_model() end ==================================
2024-09-06 22:52:43,281:INFO:Creating metrics dataframe
2024-09-06 22:52:43,293:INFO:Initializing Extreme Gradient Boosting
2024-09-06 22:52:43,293:INFO:Total runtime is 0.4506948788960775 minutes
2024-09-06 22:52:43,298:INFO:SubProcess create_model() called ==================================
2024-09-06 22:52:43,298:INFO:Initializing create_model()
2024-09-06 22:52:43,299:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000288CF65A290>, estimator=xgboost, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000288D1C19F90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-06 22:52:43,299:INFO:Checking exceptions
2024-09-06 22:52:43,299:INFO:Importing libraries
2024-09-06 22:52:43,299:INFO:Copying training dataset
2024-09-06 22:52:43,315:INFO:Defining folds
2024-09-06 22:52:43,316:INFO:Declaring metric variables
2024-09-06 22:52:43,319:INFO:Importing untrained model
2024-09-06 22:52:43,325:INFO:Extreme Gradient Boosting Imported successfully
2024-09-06 22:52:43,344:INFO:Starting cross validation
2024-09-06 22:52:43,345:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-09-06 22:52:44,377:INFO:Calculating mean and std
2024-09-06 22:52:44,380:INFO:Creating metrics dataframe
2024-09-06 22:52:44,383:INFO:Uploading results into container
2024-09-06 22:52:44,384:INFO:Uploading model into container now
2024-09-06 22:52:44,384:INFO:_master_model_container: 13
2024-09-06 22:52:44,384:INFO:_display_container: 2
2024-09-06 22:52:44,386:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-09-06 22:52:44,386:INFO:create_model() successfully completed......................................
2024-09-06 22:52:44,529:INFO:SubProcess create_model() end ==================================
2024-09-06 22:52:44,530:INFO:Creating metrics dataframe
2024-09-06 22:52:44,541:INFO:Initializing Light Gradient Boosting Machine
2024-09-06 22:52:44,541:INFO:Total runtime is 0.4714988032976787 minutes
2024-09-06 22:52:44,546:INFO:SubProcess create_model() called ==================================
2024-09-06 22:52:44,546:INFO:Initializing create_model()
2024-09-06 22:52:44,546:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000288CF65A290>, estimator=lightgbm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000288D1C19F90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-06 22:52:44,546:INFO:Checking exceptions
2024-09-06 22:52:44,546:INFO:Importing libraries
2024-09-06 22:52:44,546:INFO:Copying training dataset
2024-09-06 22:52:44,563:INFO:Defining folds
2024-09-06 22:52:44,564:INFO:Declaring metric variables
2024-09-06 22:52:44,568:INFO:Importing untrained model
2024-09-06 22:52:44,573:INFO:Light Gradient Boosting Machine Imported successfully
2024-09-06 22:52:44,582:INFO:Starting cross validation
2024-09-06 22:52:44,583:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-09-06 22:52:45,690:INFO:Calculating mean and std
2024-09-06 22:52:45,693:INFO:Creating metrics dataframe
2024-09-06 22:52:45,699:INFO:Uploading results into container
2024-09-06 22:52:45,702:INFO:Uploading model into container now
2024-09-06 22:52:45,703:INFO:_master_model_container: 14
2024-09-06 22:52:45,703:INFO:_display_container: 2
2024-09-06 22:52:45,704:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-09-06 22:52:45,704:INFO:create_model() successfully completed......................................
2024-09-06 22:52:45,872:INFO:SubProcess create_model() end ==================================
2024-09-06 22:52:45,872:INFO:Creating metrics dataframe
2024-09-06 22:52:45,886:INFO:Initializing CatBoost Classifier
2024-09-06 22:52:45,886:INFO:Total runtime is 0.49391073385874434 minutes
2024-09-06 22:52:45,890:INFO:SubProcess create_model() called ==================================
2024-09-06 22:52:45,891:INFO:Initializing create_model()
2024-09-06 22:52:45,891:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000288CF65A290>, estimator=catboost, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000288D1C19F90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-06 22:52:45,891:INFO:Checking exceptions
2024-09-06 22:52:45,891:INFO:Importing libraries
2024-09-06 22:52:45,891:INFO:Copying training dataset
2024-09-06 22:52:45,915:INFO:Defining folds
2024-09-06 22:52:45,916:INFO:Declaring metric variables
2024-09-06 22:52:45,921:INFO:Importing untrained model
2024-09-06 22:52:45,925:INFO:CatBoost Classifier Imported successfully
2024-09-06 22:52:45,939:INFO:Starting cross validation
2024-09-06 22:52:45,941:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-09-06 22:52:56,417:WARNING:c:\Users\ardav\miniconda3\envs\vsc\Lib\site-packages\sklearn\model_selection\_validation.py:547: FitFailedWarning: 
4 fits failed out of a total of 5.
The score on these train-test partitions for these parameters will be set to 0.0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
4 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\ardav\miniconda3\envs\vsc\Lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\ardav\miniconda3\envs\vsc\Lib\site-packages\pycaret\internal\pipeline.py", line 278, in fit
    fitted_estimator = self._memory_fit(
                       ^^^^^^^^^^^^^^^^^
  File "c:\Users\ardav\miniconda3\envs\vsc\Lib\site-packages\joblib\memory.py", line 349, in __call__
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\ardav\miniconda3\envs\vsc\Lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\ardav\miniconda3\envs\vsc\Lib\site-packages\catboost\core.py", line 5220, in fit
    self._fit(X, y, cat_features, text_features, embedding_features, None, sample_weight, None, None, None, None, baseline, use_best_model,
  File "c:\Users\ardav\miniconda3\envs\vsc\Lib\site-packages\catboost\core.py", line 2400, in _fit
    self._train(
  File "c:\Users\ardav\miniconda3\envs\vsc\Lib\site-packages\catboost\core.py", line 1780, in _train
    self._object._train(train_pool, test_pool, params, allow_clear_pool, init_model._object if init_model else None)
  File "_catboost.pyx", line 4833, in _catboost._CatBoost._train
  File "_catboost.pyx", line 4882, in _catboost._CatBoost._train
_catboost.CatBoostError: C:/Go_Agent/pipelines/BuildMaster/catboost.git/catboost/libs/train_lib/dir_helper.cpp:20: Can't create train working dir: catboost_info

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2024-09-06 22:52:56,418:INFO:Calculating mean and std
2024-09-06 22:52:56,419:INFO:Creating metrics dataframe
2024-09-06 22:52:56,421:INFO:Uploading results into container
2024-09-06 22:52:56,422:INFO:Uploading model into container now
2024-09-06 22:52:56,422:INFO:_master_model_container: 15
2024-09-06 22:52:56,422:INFO:_display_container: 2
2024-09-06 22:52:56,422:INFO:<catboost.core.CatBoostClassifier object at 0x00000288D190D710>
2024-09-06 22:52:56,423:INFO:create_model() successfully completed......................................
2024-09-06 22:52:56,562:WARNING:create_model() for <catboost.core.CatBoostClassifier object at 0x00000288D190D710> raised an exception or returned all 0.0, trying without fit_kwargs:
2024-09-06 22:52:56,564:WARNING:Traceback (most recent call last):
  File "c:\Users\ardav\miniconda3\envs\vsc\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 797, in compare_models
    np.sum(
AssertionError

2024-09-06 22:52:56,564:INFO:Initializing create_model()
2024-09-06 22:52:56,564:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000288CF65A290>, estimator=catboost, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000288D1C19F90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-06 22:52:56,564:INFO:Checking exceptions
2024-09-06 22:52:56,564:INFO:Importing libraries
2024-09-06 22:52:56,564:INFO:Copying training dataset
2024-09-06 22:52:56,583:INFO:Defining folds
2024-09-06 22:52:56,583:INFO:Declaring metric variables
2024-09-06 22:52:56,587:INFO:Importing untrained model
2024-09-06 22:52:56,592:INFO:CatBoost Classifier Imported successfully
2024-09-06 22:52:56,601:INFO:Starting cross validation
2024-09-06 22:52:56,602:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-09-06 22:53:21,079:INFO:Calculating mean and std
2024-09-06 22:53:21,081:INFO:Creating metrics dataframe
2024-09-06 22:53:21,091:INFO:Uploading results into container
2024-09-06 22:53:21,093:INFO:Uploading model into container now
2024-09-06 22:53:21,095:INFO:_master_model_container: 16
2024-09-06 22:53:21,095:INFO:_display_container: 2
2024-09-06 22:53:21,095:INFO:<catboost.core.CatBoostClassifier object at 0x00000288D0D4C910>
2024-09-06 22:53:21,095:INFO:create_model() successfully completed......................................
2024-09-06 22:53:21,320:INFO:SubProcess create_model() end ==================================
2024-09-06 22:53:21,320:INFO:Creating metrics dataframe
2024-09-06 22:53:21,344:INFO:Initializing Dummy Classifier
2024-09-06 22:53:21,344:INFO:Total runtime is 1.0848775823911032 minutes
2024-09-06 22:53:21,355:INFO:SubProcess create_model() called ==================================
2024-09-06 22:53:21,355:INFO:Initializing create_model()
2024-09-06 22:53:21,356:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000288CF65A290>, estimator=dummy, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000288D1C19F90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-06 22:53:21,356:INFO:Checking exceptions
2024-09-06 22:53:21,356:INFO:Importing libraries
2024-09-06 22:53:21,357:INFO:Copying training dataset
2024-09-06 22:53:21,408:INFO:Defining folds
2024-09-06 22:53:21,409:INFO:Declaring metric variables
2024-09-06 22:53:21,420:INFO:Importing untrained model
2024-09-06 22:53:21,432:INFO:Dummy Classifier Imported successfully
2024-09-06 22:53:21,449:INFO:Starting cross validation
2024-09-06 22:53:21,451:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-09-06 22:53:21,568:WARNING:c:\Users\ardav\miniconda3\envs\vsc\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-06 22:53:21,573:WARNING:c:\Users\ardav\miniconda3\envs\vsc\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-06 22:53:21,598:WARNING:c:\Users\ardav\miniconda3\envs\vsc\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-06 22:53:21,604:WARNING:c:\Users\ardav\miniconda3\envs\vsc\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-06 22:53:21,601:WARNING:c:\Users\ardav\miniconda3\envs\vsc\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-06 22:53:21,626:INFO:Calculating mean and std
2024-09-06 22:53:21,646:INFO:Creating metrics dataframe
2024-09-06 22:53:21,657:INFO:Uploading results into container
2024-09-06 22:53:21,659:INFO:Uploading model into container now
2024-09-06 22:53:21,661:INFO:_master_model_container: 17
2024-09-06 22:53:21,661:INFO:_display_container: 2
2024-09-06 22:53:21,662:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2024-09-06 22:53:21,662:INFO:create_model() successfully completed......................................
2024-09-06 22:53:21,888:INFO:SubProcess create_model() end ==================================
2024-09-06 22:53:21,888:INFO:Creating metrics dataframe
2024-09-06 22:53:21,939:INFO:Initializing create_model()
2024-09-06 22:53:21,940:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000288CF65A290>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-06 22:53:21,940:INFO:Checking exceptions
2024-09-06 22:53:21,946:INFO:Importing libraries
2024-09-06 22:53:21,946:INFO:Copying training dataset
2024-09-06 22:53:21,991:INFO:Defining folds
2024-09-06 22:53:21,992:INFO:Declaring metric variables
2024-09-06 22:53:21,992:INFO:Importing untrained model
2024-09-06 22:53:21,992:INFO:Declaring custom model
2024-09-06 22:53:21,994:INFO:Light Gradient Boosting Machine Imported successfully
2024-09-06 22:53:21,995:INFO:Cross validation set to False
2024-09-06 22:53:21,996:INFO:Fitting Model
2024-09-06 22:53:22,072:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-09-06 22:53:22,073:INFO:[LightGBM] [Info] Number of positive: 4390, number of negative: 13834
2024-09-06 22:53:22,079:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003407 seconds.
2024-09-06 22:53:22,079:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-09-06 22:53:22,079:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-09-06 22:53:22,079:INFO:[LightGBM] [Info] Total Bins 665
2024-09-06 22:53:22,080:INFO:[LightGBM] [Info] Number of data points in the train set: 18224, number of used features: 15
2024-09-06 22:53:22,081:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.240891 -> initscore=-1.147800
2024-09-06 22:53:22,081:INFO:[LightGBM] [Info] Start training from score -1.147800
2024-09-06 22:53:22,396:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-09-06 22:53:22,396:INFO:create_model() successfully completed......................................
2024-09-06 22:53:22,611:INFO:_master_model_container: 17
2024-09-06 22:53:22,611:INFO:_display_container: 2
2024-09-06 22:53:22,612:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-09-06 22:53:22,612:INFO:compare_models() successfully completed......................................
2024-09-06 22:53:22,613:INFO:Initializing create_model()
2024-09-06 22:53:22,613:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000288CF65A290>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-06 22:53:22,613:INFO:Checking exceptions
2024-09-06 22:53:22,631:INFO:Importing libraries
2024-09-06 22:53:22,632:INFO:Copying training dataset
2024-09-06 22:53:22,658:INFO:Defining folds
2024-09-06 22:53:22,658:INFO:Declaring metric variables
2024-09-06 22:53:22,664:INFO:Importing untrained model
2024-09-06 22:53:22,664:INFO:Declaring custom model
2024-09-06 22:53:22,672:INFO:Light Gradient Boosting Machine Imported successfully
2024-09-06 22:53:22,684:INFO:Starting cross validation
2024-09-06 22:53:22,685:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-06 22:53:25,466:INFO:Calculating mean and std
2024-09-06 22:53:25,468:INFO:Creating metrics dataframe
2024-09-06 22:53:25,478:INFO:Finalizing model
2024-09-06 22:53:25,539:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-09-06 22:53:25,540:INFO:[LightGBM] [Info] Number of positive: 4390, number of negative: 13834
2024-09-06 22:53:25,543:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001064 seconds.
2024-09-06 22:53:25,543:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-09-06 22:53:25,543:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-09-06 22:53:25,543:INFO:[LightGBM] [Info] Total Bins 665
2024-09-06 22:53:25,543:INFO:[LightGBM] [Info] Number of data points in the train set: 18224, number of used features: 15
2024-09-06 22:53:25,544:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.240891 -> initscore=-1.147800
2024-09-06 22:53:25,544:INFO:[LightGBM] [Info] Start training from score -1.147800
2024-09-06 22:53:25,772:INFO:Uploading results into container
2024-09-06 22:53:25,775:INFO:Uploading model into container now
2024-09-06 22:53:25,795:INFO:_master_model_container: 18
2024-09-06 22:53:25,795:INFO:_display_container: 3
2024-09-06 22:53:25,796:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-09-06 22:53:25,796:INFO:create_model() successfully completed......................................
2024-09-06 22:53:25,978:INFO:Initializing tune_model()
2024-09-06 22:53:25,978:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000288CF65A290>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=F1, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2024-09-06 22:53:25,978:INFO:Checking exceptions
2024-09-06 22:53:26,002:INFO:Copying training dataset
2024-09-06 22:53:26,014:INFO:Checking base model
2024-09-06 22:53:26,015:INFO:Base model : Light Gradient Boosting Machine
2024-09-06 22:53:26,019:INFO:Declaring metric variables
2024-09-06 22:53:26,025:INFO:Defining Hyperparameters
2024-09-06 22:53:26,179:INFO:Tuning with n_jobs=-1
2024-09-06 22:53:26,179:INFO:Initializing RandomizedSearchCV
2024-09-06 22:53:54,827:INFO:best_params: {'actual_estimator__reg_lambda': 3, 'actual_estimator__reg_alpha': 2, 'actual_estimator__num_leaves': 70, 'actual_estimator__n_estimators': 260, 'actual_estimator__min_split_gain': 0.9, 'actual_estimator__min_child_samples': 41, 'actual_estimator__learning_rate': 0.1, 'actual_estimator__feature_fraction': 0.4, 'actual_estimator__bagging_freq': 2, 'actual_estimator__bagging_fraction': 0.6}
2024-09-06 22:53:54,828:INFO:Hyperparameter search completed
2024-09-06 22:53:54,828:INFO:SubProcess create_model() called ==================================
2024-09-06 22:53:54,829:INFO:Initializing create_model()
2024-09-06 22:53:54,830:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000288CF65A290>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000288D0DE7550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 3, 'reg_alpha': 2, 'num_leaves': 70, 'n_estimators': 260, 'min_split_gain': 0.9, 'min_child_samples': 41, 'learning_rate': 0.1, 'feature_fraction': 0.4, 'bagging_freq': 2, 'bagging_fraction': 0.6})
2024-09-06 22:53:54,830:INFO:Checking exceptions
2024-09-06 22:53:54,830:INFO:Importing libraries
2024-09-06 22:53:54,830:INFO:Copying training dataset
2024-09-06 22:53:54,864:INFO:Defining folds
2024-09-06 22:53:54,865:INFO:Declaring metric variables
2024-09-06 22:53:54,871:INFO:Importing untrained model
2024-09-06 22:53:54,872:INFO:Declaring custom model
2024-09-06 22:53:54,880:INFO:Light Gradient Boosting Machine Imported successfully
2024-09-06 22:53:54,892:INFO:Starting cross validation
2024-09-06 22:53:54,893:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-06 22:53:57,298:INFO:Calculating mean and std
2024-09-06 22:53:57,300:INFO:Creating metrics dataframe
2024-09-06 22:53:57,310:INFO:Finalizing model
2024-09-06 22:53:57,351:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-09-06 22:53:57,351:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-09-06 22:53:57,352:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-09-06 22:53:57,365:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-09-06 22:53:57,366:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-09-06 22:53:57,366:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-09-06 22:53:57,366:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-09-06 22:53:57,366:INFO:[LightGBM] [Info] Number of positive: 4390, number of negative: 13834
2024-09-06 22:53:57,369:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000889 seconds.
2024-09-06 22:53:57,369:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-09-06 22:53:57,369:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-09-06 22:53:57,370:INFO:[LightGBM] [Info] Total Bins 665
2024-09-06 22:53:57,370:INFO:[LightGBM] [Info] Number of data points in the train set: 18224, number of used features: 15
2024-09-06 22:53:57,370:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.240891 -> initscore=-1.147800
2024-09-06 22:53:57,370:INFO:[LightGBM] [Info] Start training from score -1.147800
2024-09-06 22:53:57,373:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,381:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,405:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,412:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,416:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,423:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,433:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,441:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,444:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,446:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,449:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,453:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,473:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,479:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,481:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,489:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,495:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,502:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,505:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,509:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,518:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,520:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,523:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,532:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,534:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,549:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,555:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,557:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,559:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,597:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,600:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,617:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,621:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,629:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,635:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,647:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,651:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,653:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,655:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,656:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,658:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,661:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,668:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,669:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,672:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,675:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,676:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,679:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,680:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,683:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,684:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,686:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,687:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,687:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-09-06 22:53:57,688:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,689:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,691:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,692:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,694:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,695:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-09-06 22:53:57,695:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,696:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,698:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,699:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,700:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,702:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,703:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,705:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,706:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,707:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,708:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,712:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,713:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-09-06 22:53:57,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,715:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,719:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,722:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,723:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,725:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,726:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,728:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,729:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,731:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,733:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,735:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,736:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,736:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,736:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-09-06 22:53:57,737:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,737:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-09-06 22:53:57,738:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,739:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,740:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,741:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,742:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,745:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,748:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,751:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,752:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,756:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,758:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,761:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,763:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,765:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,768:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,769:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,771:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,772:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,774:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,775:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,775:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,778:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,778:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,781:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,782:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,782:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-09-06 22:53:57,783:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,785:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,785:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,786:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,787:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,788:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,789:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,790:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,790:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-09-06 22:53:57,792:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,792:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,792:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-09-06 22:53:57,793:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,794:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,794:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,795:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,796:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,797:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,799:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,801:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,802:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,803:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,804:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,806:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,808:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,811:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-09-06 22:53:57,812:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,815:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:53:57,836:INFO:Uploading results into container
2024-09-06 22:53:57,839:INFO:Uploading model into container now
2024-09-06 22:53:57,840:INFO:_master_model_container: 19
2024-09-06 22:53:57,840:INFO:_display_container: 4
2024-09-06 22:53:57,841:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-09-06 22:53:57,841:INFO:create_model() successfully completed......................................
2024-09-06 22:53:58,027:INFO:SubProcess create_model() end ==================================
2024-09-06 22:53:58,027:INFO:choose_better activated
2024-09-06 22:53:58,032:INFO:SubProcess create_model() called ==================================
2024-09-06 22:53:58,033:INFO:Initializing create_model()
2024-09-06 22:53:58,033:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000288CF65A290>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-06 22:53:58,033:INFO:Checking exceptions
2024-09-06 22:53:58,036:INFO:Importing libraries
2024-09-06 22:53:58,036:INFO:Copying training dataset
2024-09-06 22:53:58,057:INFO:Defining folds
2024-09-06 22:53:58,058:INFO:Declaring metric variables
2024-09-06 22:53:58,058:INFO:Importing untrained model
2024-09-06 22:53:58,058:INFO:Declaring custom model
2024-09-06 22:53:58,059:INFO:Light Gradient Boosting Machine Imported successfully
2024-09-06 22:53:58,059:INFO:Starting cross validation
2024-09-06 22:53:58,060:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-06 22:53:59,617:INFO:Calculating mean and std
2024-09-06 22:53:59,618:INFO:Creating metrics dataframe
2024-09-06 22:53:59,621:INFO:Finalizing model
2024-09-06 22:53:59,674:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-09-06 22:53:59,674:INFO:[LightGBM] [Info] Number of positive: 4390, number of negative: 13834
2024-09-06 22:53:59,677:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000959 seconds.
2024-09-06 22:53:59,678:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-09-06 22:53:59,678:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-09-06 22:53:59,678:INFO:[LightGBM] [Info] Total Bins 665
2024-09-06 22:53:59,678:INFO:[LightGBM] [Info] Number of data points in the train set: 18224, number of used features: 15
2024-09-06 22:53:59,678:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.240891 -> initscore=-1.147800
2024-09-06 22:53:59,678:INFO:[LightGBM] [Info] Start training from score -1.147800
2024-09-06 22:53:59,882:INFO:Uploading results into container
2024-09-06 22:53:59,883:INFO:Uploading model into container now
2024-09-06 22:53:59,884:INFO:_master_model_container: 20
2024-09-06 22:53:59,884:INFO:_display_container: 5
2024-09-06 22:53:59,884:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-09-06 22:53:59,884:INFO:create_model() successfully completed......................................
2024-09-06 22:54:00,035:INFO:SubProcess create_model() end ==================================
2024-09-06 22:54:00,036:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for F1 is 0.6982
2024-09-06 22:54:00,036:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for F1 is 0.6971
2024-09-06 22:54:00,037:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2024-09-06 22:54:00,037:INFO:choose_better completed
2024-09-06 22:54:00,037:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2024-09-06 22:54:00,048:INFO:_master_model_container: 20
2024-09-06 22:54:00,049:INFO:_display_container: 4
2024-09-06 22:54:00,049:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-09-06 22:54:00,049:INFO:tune_model() successfully completed......................................
2024-09-06 22:54:00,225:INFO:Initializing finalize_model()
2024-09-06 22:54:00,226:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000288CF65A290>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-09-06 22:54:00,227:INFO:Finalizing LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-09-06 22:54:00,241:INFO:Initializing create_model()
2024-09-06 22:54:00,241:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000288CF65A290>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-09-06 22:54:00,241:INFO:Checking exceptions
2024-09-06 22:54:00,243:INFO:Importing libraries
2024-09-06 22:54:00,244:INFO:Copying training dataset
2024-09-06 22:54:00,244:INFO:Defining folds
2024-09-06 22:54:00,245:INFO:Declaring metric variables
2024-09-06 22:54:00,245:INFO:Importing untrained model
2024-09-06 22:54:00,245:INFO:Declaring custom model
2024-09-06 22:54:00,246:INFO:Light Gradient Boosting Machine Imported successfully
2024-09-06 22:54:00,247:INFO:Cross validation set to False
2024-09-06 22:54:00,247:INFO:Fitting Model
2024-09-06 22:54:00,305:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-09-06 22:54:00,306:INFO:[LightGBM] [Info] Number of positive: 6272, number of negative: 19763
2024-09-06 22:54:00,310:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001252 seconds.
2024-09-06 22:54:00,310:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-09-06 22:54:00,310:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-09-06 22:54:00,310:INFO:[LightGBM] [Info] Total Bins 681
2024-09-06 22:54:00,310:INFO:[LightGBM] [Info] Number of data points in the train set: 26035, number of used features: 15
2024-09-06 22:54:00,311:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.240906 -> initscore=-1.147716
2024-09-06 22:54:00,311:INFO:[LightGBM] [Info] Start training from score -1.147716
2024-09-06 22:54:00,522:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Tahun Kelahiran',
                                             'Kelas Pekerjaan', 'fnlwgt',
                                             'Pendidikan', 'Jenjang Pendidikan',
                                             'Status', 'Pekerjaan', 'Hubungan',
                                             'Etnis', 'sex', 'pendapatan',
                                             'pengeluaran', 'hours per week',
                                             'Asal Negara', 'jumlah_anak'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-09-06 22:54:00,522:INFO:create_model() successfully completed......................................
2024-09-06 22:54:00,676:INFO:_master_model_container: 20
2024-09-06 22:54:00,676:INFO:_display_container: 4
2024-09-06 22:54:00,682:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Tahun Kelahiran',
                                             'Kelas Pekerjaan', 'fnlwgt',
                                             'Pendidikan', 'Jenjang Pendidikan',
                                             'Status', 'Pekerjaan', 'Hubungan',
                                             'Etnis', 'sex', 'pendapatan',
                                             'pengeluaran', 'hours per week',
                                             'Asal Negara', 'jumlah_anak'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-09-06 22:54:00,682:INFO:finalize_model() successfully completed......................................
2024-09-06 22:54:00,812:INFO:Initializing predict_model()
2024-09-06 22:54:00,813:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000288CF65A290>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Tahun Kelahiran',
                                             'Kelas Pekerjaan', 'fnlwgt',
                                             'Pendidikan', 'Jenjang Pendidikan',
                                             'Status', 'Pekerjaan', 'Hubungan',
                                             'Etnis', 'sex', 'pendapatan',
                                             'pengeluaran', 'hours per week',
                                             'Asal Negara', 'jumlah_anak'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000288D19CD8A0>)
2024-09-06 22:54:00,813:INFO:Checking exceptions
2024-09-06 22:54:00,813:INFO:Preloading libraries
2024-09-06 22:54:00,814:INFO:Set up data.
2024-09-06 22:54:00,831:INFO:Set up index.
2024-09-06 22:54:48,043:INFO:PyCaret ClassificationExperiment
2024-09-06 22:54:48,043:INFO:Logging name: clf-default-name
2024-09-06 22:54:48,043:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-09-06 22:54:48,043:INFO:version 3.3.2
2024-09-06 22:54:48,043:INFO:Initializing setup()
2024-09-06 22:54:48,043:INFO:self.USI: ac01
2024-09-06 22:54:48,043:INFO:self._variable_keys: {'idx', 'y', 'y_train', 'seed', 'USI', 'memory', 'fix_imbalance', 'exp_id', 'exp_name_log', 'data', 'is_multiclass', '_available_plots', 'html_param', 'X_train', 'log_plots_param', 'fold_generator', 'X_test', 'y_test', 'n_jobs_param', 'X', 'gpu_param', 'pipeline', 'fold_groups_param', 'fold_shuffle_param', '_ml_usecase', 'target_param', 'gpu_n_jobs_param', 'logging_param'}
2024-09-06 22:54:48,044:INFO:Checking environment
2024-09-06 22:54:48,044:INFO:python_version: 3.11.9
2024-09-06 22:54:48,044:INFO:python_build: ('main', 'Apr 19 2024 16:40:41')
2024-09-06 22:54:48,044:INFO:machine: AMD64
2024-09-06 22:54:48,044:INFO:platform: Windows-10-10.0.22631-SP0
2024-09-06 22:54:48,052:INFO:Memory: svmem(total=16867028992, available=1521545216, percent=91.0, used=15345483776, free=1521545216)
2024-09-06 22:54:48,052:INFO:Physical Core: 6
2024-09-06 22:54:48,053:INFO:Logical Core: 12
2024-09-06 22:54:48,053:INFO:Checking libraries
2024-09-06 22:54:48,053:INFO:System:
2024-09-06 22:54:48,053:INFO:    python: 3.11.9 | packaged by Anaconda, Inc. | (main, Apr 19 2024, 16:40:41) [MSC v.1916 64 bit (AMD64)]
2024-09-06 22:54:48,053:INFO:executable: c:\Users\ardav\miniconda3\envs\vsc\python.exe
2024-09-06 22:54:48,053:INFO:   machine: Windows-10-10.0.22631-SP0
2024-09-06 22:54:48,053:INFO:PyCaret required dependencies:
2024-09-06 22:54:48,053:INFO:                 pip: 23.2.1
2024-09-06 22:54:48,053:INFO:          setuptools: 67.8.0
2024-09-06 22:54:48,053:INFO:             pycaret: 3.3.2
2024-09-06 22:54:48,053:INFO:             IPython: 8.14.0
2024-09-06 22:54:48,053:INFO:          ipywidgets: 8.1.5
2024-09-06 22:54:48,053:INFO:                tqdm: 4.66.5
2024-09-06 22:54:48,053:INFO:               numpy: 1.26.4
2024-09-06 22:54:48,053:INFO:              pandas: 2.0.3
2024-09-06 22:54:48,054:INFO:              jinja2: 3.1.4
2024-09-06 22:54:48,054:INFO:               scipy: 1.10.1
2024-09-06 22:54:48,054:INFO:              joblib: 1.2.0
2024-09-06 22:54:48,054:INFO:             sklearn: 1.4.2
2024-09-06 22:54:48,054:INFO:                pyod: 2.0.1
2024-09-06 22:54:48,054:INFO:            imblearn: 0.12.3
2024-09-06 22:54:48,054:INFO:   category_encoders: 2.6.3
2024-09-06 22:54:48,054:INFO:            lightgbm: 4.5.0
2024-09-06 22:54:48,054:INFO:               numba: 0.60.0
2024-09-06 22:54:48,054:INFO:            requests: 2.32.3
2024-09-06 22:54:48,054:INFO:          matplotlib: 3.7.1
2024-09-06 22:54:48,054:INFO:          scikitplot: 0.3.7
2024-09-06 22:54:48,054:INFO:         yellowbrick: 1.5
2024-09-06 22:54:48,054:INFO:              plotly: 5.16.1
2024-09-06 22:54:48,054:INFO:    plotly-resampler: Not installed
2024-09-06 22:54:48,054:INFO:             kaleido: 0.2.1
2024-09-06 22:54:48,054:INFO:           schemdraw: 0.15
2024-09-06 22:54:48,054:INFO:         statsmodels: 0.14.2
2024-09-06 22:54:48,054:INFO:              sktime: 0.26.0
2024-09-06 22:54:48,054:INFO:               tbats: 1.1.3
2024-09-06 22:54:48,054:INFO:            pmdarima: 2.0.4
2024-09-06 22:54:48,054:INFO:              psutil: 5.9.0
2024-09-06 22:54:48,055:INFO:          markupsafe: 2.1.3
2024-09-06 22:54:48,055:INFO:             pickle5: Not installed
2024-09-06 22:54:48,055:INFO:         cloudpickle: 3.0.0
2024-09-06 22:54:48,055:INFO:         deprecation: 2.1.0
2024-09-06 22:54:48,055:INFO:              xxhash: 3.5.0
2024-09-06 22:54:48,055:INFO:           wurlitzer: Not installed
2024-09-06 22:54:48,055:INFO:PyCaret optional dependencies:
2024-09-06 22:54:48,055:INFO:                shap: Not installed
2024-09-06 22:54:48,055:INFO:           interpret: Not installed
2024-09-06 22:54:48,055:INFO:                umap: Not installed
2024-09-06 22:54:48,055:INFO:     ydata_profiling: Not installed
2024-09-06 22:54:48,055:INFO:  explainerdashboard: Not installed
2024-09-06 22:54:48,055:INFO:             autoviz: Not installed
2024-09-06 22:54:48,055:INFO:           fairlearn: Not installed
2024-09-06 22:54:48,055:INFO:          deepchecks: Not installed
2024-09-06 22:54:48,055:INFO:             xgboost: 2.1.1
2024-09-06 22:54:48,055:INFO:            catboost: 1.2.5
2024-09-06 22:54:48,055:INFO:              kmodes: Not installed
2024-09-06 22:54:48,055:INFO:             mlxtend: Not installed
2024-09-06 22:54:48,055:INFO:       statsforecast: Not installed
2024-09-06 22:54:48,055:INFO:        tune_sklearn: Not installed
2024-09-06 22:54:48,055:INFO:                 ray: Not installed
2024-09-06 22:54:48,055:INFO:            hyperopt: Not installed
2024-09-06 22:54:48,055:INFO:              optuna: 4.0.0
2024-09-06 22:54:48,055:INFO:               skopt: Not installed
2024-09-06 22:54:48,055:INFO:              mlflow: Not installed
2024-09-06 22:54:48,055:INFO:              gradio: 4.41.0
2024-09-06 22:54:48,055:INFO:             fastapi: 0.112.1
2024-09-06 22:54:48,055:INFO:             uvicorn: 0.30.6
2024-09-06 22:54:48,055:INFO:              m2cgen: Not installed
2024-09-06 22:54:48,056:INFO:           evidently: Not installed
2024-09-06 22:54:48,056:INFO:               fugue: Not installed
2024-09-06 22:54:48,056:INFO:           streamlit: 1.38.0
2024-09-06 22:54:48,056:INFO:             prophet: Not installed
2024-09-06 22:54:48,056:INFO:None
2024-09-06 22:54:48,056:INFO:Set up data.
2024-09-06 22:54:48,070:INFO:Set up folding strategy.
2024-09-06 22:54:48,070:INFO:Set up train/test split.
2024-09-06 22:54:48,096:INFO:Set up index.
2024-09-06 22:54:48,097:INFO:Assigning column types.
2024-09-06 22:54:48,123:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-09-06 22:54:48,222:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-09-06 22:54:48,224:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-09-06 22:54:48,269:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-06 22:54:48,272:INFO:Soft dependency imported: catboost: 1.2.5
2024-09-06 22:54:48,327:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-09-06 22:54:48,329:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-09-06 22:54:48,357:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-06 22:54:48,361:INFO:Soft dependency imported: catboost: 1.2.5
2024-09-06 22:54:48,361:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-09-06 22:54:48,414:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-09-06 22:54:48,447:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-06 22:54:48,452:INFO:Soft dependency imported: catboost: 1.2.5
2024-09-06 22:54:48,513:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-09-06 22:54:48,551:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-06 22:54:48,554:INFO:Soft dependency imported: catboost: 1.2.5
2024-09-06 22:54:48,555:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-09-06 22:54:48,663:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-06 22:54:48,666:INFO:Soft dependency imported: catboost: 1.2.5
2024-09-06 22:54:48,750:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-06 22:54:48,752:INFO:Soft dependency imported: catboost: 1.2.5
2024-09-06 22:54:48,754:INFO:Preparing preprocessing pipeline...
2024-09-06 22:54:48,758:INFO:Set up simple imputation.
2024-09-06 22:54:48,761:INFO:Set up column name cleaning.
2024-09-06 22:54:48,812:INFO:Finished creating preprocessing pipeline.
2024-09-06 22:54:48,816:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\ardav\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Tahun Kelahiran',
                                             'Kelas Pekerjaan', 'fnlwgt',
                                             'Pendidikan', 'Jenjang Pendidikan',
                                             'Status', 'Pekerjaan', 'Hubungan',
                                             'Etnis', 'sex', 'pendapatan',
                                             'pengeluaran', 'hours per week',
                                             'Asal Negara', 'jumlah_anak'],
                                    transformer...
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2024-09-06 22:54:48,816:INFO:Creating final display dataframe.
2024-09-06 22:54:48,964:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target            income
2                   Target type            Binary
3           Original data shape       (26035, 16)
4        Transformed data shape       (26035, 16)
5   Transformed train set shape       (18224, 16)
6    Transformed test set shape        (7811, 16)
7              Numeric features                15
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              ac01
2024-09-06 22:54:49,058:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-06 22:54:49,061:INFO:Soft dependency imported: catboost: 1.2.5
2024-09-06 22:54:49,141:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-06 22:54:49,143:INFO:Soft dependency imported: catboost: 1.2.5
2024-09-06 22:54:49,145:INFO:setup() successfully completed in 1.11s...............
2024-09-06 22:54:49,145:INFO:Initializing compare_models()
2024-09-06 22:54:49,145:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000288D1925710>, include=None, exclude=None, fold=5, round=4, cross_validation=True, sort=F1, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x00000288D1925710>, 'include': None, 'exclude': None, 'fold': 5, 'round': 4, 'cross_validation': True, 'sort': 'F1', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2024-09-06 22:54:49,145:INFO:Checking exceptions
2024-09-06 22:54:49,155:INFO:Preparing display monitor
2024-09-06 22:54:49,182:INFO:Initializing Logistic Regression
2024-09-06 22:54:49,183:INFO:Total runtime is 8.559226989746093e-06 minutes
2024-09-06 22:54:49,188:INFO:SubProcess create_model() called ==================================
2024-09-06 22:54:49,189:INFO:Initializing create_model()
2024-09-06 22:54:49,189:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000288D1925710>, estimator=lr, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000288D1976790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-06 22:54:49,189:INFO:Checking exceptions
2024-09-06 22:54:49,189:INFO:Importing libraries
2024-09-06 22:54:49,189:INFO:Copying training dataset
2024-09-06 22:54:49,216:INFO:Defining folds
2024-09-06 22:54:49,216:INFO:Declaring metric variables
2024-09-06 22:54:49,221:INFO:Importing untrained model
2024-09-06 22:54:49,229:INFO:Logistic Regression Imported successfully
2024-09-06 22:54:49,241:INFO:Starting cross validation
2024-09-06 22:54:49,242:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-09-06 22:54:51,447:WARNING:c:\Users\ardav\miniconda3\envs\vsc\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-09-06 22:54:51,476:WARNING:c:\Users\ardav\miniconda3\envs\vsc\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-09-06 22:54:51,485:WARNING:c:\Users\ardav\miniconda3\envs\vsc\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-09-06 22:54:51,498:WARNING:c:\Users\ardav\miniconda3\envs\vsc\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-09-06 22:54:51,505:WARNING:c:\Users\ardav\miniconda3\envs\vsc\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-09-06 22:54:51,548:INFO:Calculating mean and std
2024-09-06 22:54:51,550:INFO:Creating metrics dataframe
2024-09-06 22:54:51,553:INFO:Uploading results into container
2024-09-06 22:54:51,554:INFO:Uploading model into container now
2024-09-06 22:54:51,554:INFO:_master_model_container: 1
2024-09-06 22:54:51,555:INFO:_display_container: 2
2024-09-06 22:54:51,556:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-09-06 22:54:51,556:INFO:create_model() successfully completed......................................
2024-09-06 22:54:51,803:INFO:SubProcess create_model() end ==================================
2024-09-06 22:54:51,803:INFO:Creating metrics dataframe
2024-09-06 22:54:51,812:INFO:Initializing K Neighbors Classifier
2024-09-06 22:54:51,812:INFO:Total runtime is 0.04382876952489217 minutes
2024-09-06 22:54:51,817:INFO:SubProcess create_model() called ==================================
2024-09-06 22:54:51,817:INFO:Initializing create_model()
2024-09-06 22:54:51,817:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000288D1925710>, estimator=knn, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000288D1976790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-06 22:54:51,818:INFO:Checking exceptions
2024-09-06 22:54:51,818:INFO:Importing libraries
2024-09-06 22:54:51,818:INFO:Copying training dataset
2024-09-06 22:54:51,861:INFO:Defining folds
2024-09-06 22:54:51,861:INFO:Declaring metric variables
2024-09-06 22:54:51,875:INFO:Importing untrained model
2024-09-06 22:54:51,887:INFO:K Neighbors Classifier Imported successfully
2024-09-06 22:54:51,909:INFO:Starting cross validation
2024-09-06 22:54:51,913:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-09-06 22:54:52,519:INFO:Calculating mean and std
2024-09-06 22:54:52,521:INFO:Creating metrics dataframe
2024-09-06 22:54:52,524:INFO:Uploading results into container
2024-09-06 22:54:52,525:INFO:Uploading model into container now
2024-09-06 22:54:52,526:INFO:_master_model_container: 2
2024-09-06 22:54:52,526:INFO:_display_container: 2
2024-09-06 22:54:52,527:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-09-06 22:54:52,527:INFO:create_model() successfully completed......................................
2024-09-06 22:54:52,727:INFO:SubProcess create_model() end ==================================
2024-09-06 22:54:52,727:INFO:Creating metrics dataframe
2024-09-06 22:54:52,736:INFO:Initializing Naive Bayes
2024-09-06 22:54:52,736:INFO:Total runtime is 0.0592329184214274 minutes
2024-09-06 22:54:52,740:INFO:SubProcess create_model() called ==================================
2024-09-06 22:54:52,740:INFO:Initializing create_model()
2024-09-06 22:54:52,741:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000288D1925710>, estimator=nb, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000288D1976790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-06 22:54:52,741:INFO:Checking exceptions
2024-09-06 22:54:52,741:INFO:Importing libraries
2024-09-06 22:54:52,741:INFO:Copying training dataset
2024-09-06 22:54:52,757:INFO:Defining folds
2024-09-06 22:54:52,757:INFO:Declaring metric variables
2024-09-06 22:54:52,762:INFO:Importing untrained model
2024-09-06 22:54:52,768:INFO:Naive Bayes Imported successfully
2024-09-06 22:54:52,777:INFO:Starting cross validation
2024-09-06 22:54:52,778:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-09-06 22:54:52,928:INFO:Calculating mean and std
2024-09-06 22:54:52,931:INFO:Creating metrics dataframe
2024-09-06 22:54:52,934:INFO:Uploading results into container
2024-09-06 22:54:52,935:INFO:Uploading model into container now
2024-09-06 22:54:52,936:INFO:_master_model_container: 3
2024-09-06 22:54:52,936:INFO:_display_container: 2
2024-09-06 22:54:52,936:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-09-06 22:54:52,937:INFO:create_model() successfully completed......................................
2024-09-06 22:54:53,187:INFO:SubProcess create_model() end ==================================
2024-09-06 22:54:53,187:INFO:Creating metrics dataframe
2024-09-06 22:54:53,206:INFO:Initializing Decision Tree Classifier
2024-09-06 22:54:53,206:INFO:Total runtime is 0.06706035534540812 minutes
2024-09-06 22:54:53,211:INFO:SubProcess create_model() called ==================================
2024-09-06 22:54:53,212:INFO:Initializing create_model()
2024-09-06 22:54:53,212:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000288D1925710>, estimator=dt, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000288D1976790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-06 22:54:53,212:INFO:Checking exceptions
2024-09-06 22:54:53,212:INFO:Importing libraries
2024-09-06 22:54:53,212:INFO:Copying training dataset
2024-09-06 22:54:53,246:INFO:Defining folds
2024-09-06 22:54:53,246:INFO:Declaring metric variables
2024-09-06 22:54:53,255:INFO:Importing untrained model
2024-09-06 22:54:53,265:INFO:Decision Tree Classifier Imported successfully
2024-09-06 22:54:53,282:INFO:Starting cross validation
2024-09-06 22:54:53,283:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-09-06 22:54:53,567:INFO:Calculating mean and std
2024-09-06 22:54:53,569:INFO:Creating metrics dataframe
2024-09-06 22:54:53,573:INFO:Uploading results into container
2024-09-06 22:54:53,573:INFO:Uploading model into container now
2024-09-06 22:54:53,574:INFO:_master_model_container: 4
2024-09-06 22:54:53,574:INFO:_display_container: 2
2024-09-06 22:54:53,575:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2024-09-06 22:54:53,575:INFO:create_model() successfully completed......................................
2024-09-06 22:54:53,823:INFO:SubProcess create_model() end ==================================
2024-09-06 22:54:53,823:INFO:Creating metrics dataframe
2024-09-06 22:54:53,838:INFO:Initializing SVM - Linear Kernel
2024-09-06 22:54:53,838:INFO:Total runtime is 0.07759354909261068 minutes
2024-09-06 22:54:53,844:INFO:SubProcess create_model() called ==================================
2024-09-06 22:54:53,845:INFO:Initializing create_model()
2024-09-06 22:54:53,845:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000288D1925710>, estimator=svm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000288D1976790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-06 22:54:53,845:INFO:Checking exceptions
2024-09-06 22:54:53,845:INFO:Importing libraries
2024-09-06 22:54:53,845:INFO:Copying training dataset
2024-09-06 22:54:53,872:INFO:Defining folds
2024-09-06 22:54:53,872:INFO:Declaring metric variables
2024-09-06 22:54:53,877:INFO:Importing untrained model
2024-09-06 22:54:53,883:INFO:SVM - Linear Kernel Imported successfully
2024-09-06 22:54:53,893:INFO:Starting cross validation
2024-09-06 22:54:53,894:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-09-06 22:54:54,308:INFO:Calculating mean and std
2024-09-06 22:54:54,309:INFO:Creating metrics dataframe
2024-09-06 22:54:54,311:INFO:Uploading results into container
2024-09-06 22:54:54,312:INFO:Uploading model into container now
2024-09-06 22:54:54,313:INFO:_master_model_container: 5
2024-09-06 22:54:54,313:INFO:_display_container: 2
2024-09-06 22:54:54,313:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-09-06 22:54:54,313:INFO:create_model() successfully completed......................................
2024-09-06 22:54:54,531:INFO:SubProcess create_model() end ==================================
2024-09-06 22:54:54,532:INFO:Creating metrics dataframe
2024-09-06 22:54:54,541:INFO:Initializing Ridge Classifier
2024-09-06 22:54:54,541:INFO:Total runtime is 0.08931099573771159 minutes
2024-09-06 22:54:54,545:INFO:SubProcess create_model() called ==================================
2024-09-06 22:54:54,545:INFO:Initializing create_model()
2024-09-06 22:54:54,545:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000288D1925710>, estimator=ridge, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000288D1976790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-06 22:54:54,545:INFO:Checking exceptions
2024-09-06 22:54:54,545:INFO:Importing libraries
2024-09-06 22:54:54,545:INFO:Copying training dataset
2024-09-06 22:54:54,563:INFO:Defining folds
2024-09-06 22:54:54,563:INFO:Declaring metric variables
2024-09-06 22:54:54,577:INFO:Importing untrained model
2024-09-06 22:54:54,583:INFO:Ridge Classifier Imported successfully
2024-09-06 22:54:54,592:INFO:Starting cross validation
2024-09-06 22:54:54,593:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-09-06 22:54:54,700:INFO:Calculating mean and std
2024-09-06 22:54:54,702:INFO:Creating metrics dataframe
2024-09-06 22:54:54,704:INFO:Uploading results into container
2024-09-06 22:54:54,705:INFO:Uploading model into container now
2024-09-06 22:54:54,705:INFO:_master_model_container: 6
2024-09-06 22:54:54,705:INFO:_display_container: 2
2024-09-06 22:54:54,706:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2024-09-06 22:54:54,706:INFO:create_model() successfully completed......................................
2024-09-06 22:54:54,910:INFO:SubProcess create_model() end ==================================
2024-09-06 22:54:54,910:INFO:Creating metrics dataframe
2024-09-06 22:54:54,921:INFO:Initializing Random Forest Classifier
2024-09-06 22:54:54,921:INFO:Total runtime is 0.095634925365448 minutes
2024-09-06 22:54:54,926:INFO:SubProcess create_model() called ==================================
2024-09-06 22:54:54,926:INFO:Initializing create_model()
2024-09-06 22:54:54,926:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000288D1925710>, estimator=rf, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000288D1976790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-06 22:54:54,926:INFO:Checking exceptions
2024-09-06 22:54:54,927:INFO:Importing libraries
2024-09-06 22:54:54,927:INFO:Copying training dataset
2024-09-06 22:54:54,948:INFO:Defining folds
2024-09-06 22:54:54,949:INFO:Declaring metric variables
2024-09-06 22:54:54,954:INFO:Importing untrained model
2024-09-06 22:54:54,961:INFO:Random Forest Classifier Imported successfully
2024-09-06 22:54:54,971:INFO:Starting cross validation
2024-09-06 22:54:54,973:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-09-06 22:54:56,869:INFO:Calculating mean and std
2024-09-06 22:54:56,870:INFO:Creating metrics dataframe
2024-09-06 22:54:56,875:INFO:Uploading results into container
2024-09-06 22:54:56,876:INFO:Uploading model into container now
2024-09-06 22:54:56,877:INFO:_master_model_container: 7
2024-09-06 22:54:56,877:INFO:_display_container: 2
2024-09-06 22:54:56,878:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2024-09-06 22:54:56,878:INFO:create_model() successfully completed......................................
2024-09-06 22:54:57,078:INFO:SubProcess create_model() end ==================================
2024-09-06 22:54:57,078:INFO:Creating metrics dataframe
2024-09-06 22:54:57,091:INFO:Initializing Quadratic Discriminant Analysis
2024-09-06 22:54:57,091:INFO:Total runtime is 0.13180707693099974 minutes
2024-09-06 22:54:57,094:INFO:SubProcess create_model() called ==================================
2024-09-06 22:54:57,095:INFO:Initializing create_model()
2024-09-06 22:54:57,095:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000288D1925710>, estimator=qda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000288D1976790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-06 22:54:57,096:INFO:Checking exceptions
2024-09-06 22:54:57,096:INFO:Importing libraries
2024-09-06 22:54:57,096:INFO:Copying training dataset
2024-09-06 22:54:57,114:INFO:Defining folds
2024-09-06 22:54:57,114:INFO:Declaring metric variables
2024-09-06 22:54:57,119:INFO:Importing untrained model
2024-09-06 22:54:57,123:INFO:Quadratic Discriminant Analysis Imported successfully
2024-09-06 22:54:57,131:INFO:Starting cross validation
2024-09-06 22:54:57,132:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-09-06 22:54:57,273:INFO:Calculating mean and std
2024-09-06 22:54:57,276:INFO:Creating metrics dataframe
2024-09-06 22:54:57,281:INFO:Uploading results into container
2024-09-06 22:54:57,282:INFO:Uploading model into container now
2024-09-06 22:54:57,283:INFO:_master_model_container: 8
2024-09-06 22:54:57,283:INFO:_display_container: 2
2024-09-06 22:54:57,284:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-09-06 22:54:57,284:INFO:create_model() successfully completed......................................
2024-09-06 22:54:57,542:INFO:SubProcess create_model() end ==================================
2024-09-06 22:54:57,543:INFO:Creating metrics dataframe
2024-09-06 22:54:57,553:INFO:Initializing Ada Boost Classifier
2024-09-06 22:54:57,553:INFO:Total runtime is 0.13950875202814736 minutes
2024-09-06 22:54:57,558:INFO:SubProcess create_model() called ==================================
2024-09-06 22:54:57,559:INFO:Initializing create_model()
2024-09-06 22:54:57,559:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000288D1925710>, estimator=ada, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000288D1976790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-06 22:54:57,559:INFO:Checking exceptions
2024-09-06 22:54:57,559:INFO:Importing libraries
2024-09-06 22:54:57,559:INFO:Copying training dataset
2024-09-06 22:54:57,585:INFO:Defining folds
2024-09-06 22:54:57,585:INFO:Declaring metric variables
2024-09-06 22:54:57,593:INFO:Importing untrained model
2024-09-06 22:54:57,600:INFO:Ada Boost Classifier Imported successfully
2024-09-06 22:54:57,613:INFO:Starting cross validation
2024-09-06 22:54:57,615:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-09-06 22:54:57,679:WARNING:c:\Users\ardav\miniconda3\envs\vsc\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-06 22:54:57,686:WARNING:c:\Users\ardav\miniconda3\envs\vsc\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-06 22:54:57,694:WARNING:c:\Users\ardav\miniconda3\envs\vsc\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-06 22:54:57,701:WARNING:c:\Users\ardav\miniconda3\envs\vsc\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-06 22:54:57,707:WARNING:c:\Users\ardav\miniconda3\envs\vsc\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-06 22:54:58,640:INFO:Calculating mean and std
2024-09-06 22:54:58,642:INFO:Creating metrics dataframe
2024-09-06 22:54:58,645:INFO:Uploading results into container
2024-09-06 22:54:58,645:INFO:Uploading model into container now
2024-09-06 22:54:58,646:INFO:_master_model_container: 9
2024-09-06 22:54:58,646:INFO:_display_container: 2
2024-09-06 22:54:58,647:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2024-09-06 22:54:58,647:INFO:create_model() successfully completed......................................
2024-09-06 22:54:58,851:INFO:SubProcess create_model() end ==================================
2024-09-06 22:54:58,852:INFO:Creating metrics dataframe
2024-09-06 22:54:58,868:INFO:Initializing Gradient Boosting Classifier
2024-09-06 22:54:58,868:INFO:Total runtime is 0.16143016417821246 minutes
2024-09-06 22:54:58,875:INFO:SubProcess create_model() called ==================================
2024-09-06 22:54:58,875:INFO:Initializing create_model()
2024-09-06 22:54:58,875:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000288D1925710>, estimator=gbc, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000288D1976790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-06 22:54:58,876:INFO:Checking exceptions
2024-09-06 22:54:58,876:INFO:Importing libraries
2024-09-06 22:54:58,876:INFO:Copying training dataset
2024-09-06 22:54:58,901:INFO:Defining folds
2024-09-06 22:54:58,901:INFO:Declaring metric variables
2024-09-06 22:54:58,907:INFO:Importing untrained model
2024-09-06 22:54:58,916:INFO:Gradient Boosting Classifier Imported successfully
2024-09-06 22:54:58,929:INFO:Starting cross validation
2024-09-06 22:54:58,931:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-09-06 22:55:01,679:INFO:Calculating mean and std
2024-09-06 22:55:01,681:INFO:Creating metrics dataframe
2024-09-06 22:55:01,683:INFO:Uploading results into container
2024-09-06 22:55:01,684:INFO:Uploading model into container now
2024-09-06 22:55:01,684:INFO:_master_model_container: 10
2024-09-06 22:55:01,684:INFO:_display_container: 2
2024-09-06 22:55:01,685:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-09-06 22:55:01,685:INFO:create_model() successfully completed......................................
2024-09-06 22:55:01,882:INFO:SubProcess create_model() end ==================================
2024-09-06 22:55:01,882:INFO:Creating metrics dataframe
2024-09-06 22:55:01,892:INFO:Initializing Linear Discriminant Analysis
2024-09-06 22:55:01,892:INFO:Total runtime is 0.21182885964711506 minutes
2024-09-06 22:55:01,895:INFO:SubProcess create_model() called ==================================
2024-09-06 22:55:01,895:INFO:Initializing create_model()
2024-09-06 22:55:01,895:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000288D1925710>, estimator=lda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000288D1976790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-06 22:55:01,895:INFO:Checking exceptions
2024-09-06 22:55:01,896:INFO:Importing libraries
2024-09-06 22:55:01,896:INFO:Copying training dataset
2024-09-06 22:55:01,914:INFO:Defining folds
2024-09-06 22:55:01,915:INFO:Declaring metric variables
2024-09-06 22:55:01,918:INFO:Importing untrained model
2024-09-06 22:55:01,922:INFO:Linear Discriminant Analysis Imported successfully
2024-09-06 22:55:01,929:INFO:Starting cross validation
2024-09-06 22:55:01,930:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-09-06 22:55:02,114:INFO:Calculating mean and std
2024-09-06 22:55:02,116:INFO:Creating metrics dataframe
2024-09-06 22:55:02,117:INFO:Uploading results into container
2024-09-06 22:55:02,118:INFO:Uploading model into container now
2024-09-06 22:55:02,118:INFO:_master_model_container: 11
2024-09-06 22:55:02,119:INFO:_display_container: 2
2024-09-06 22:55:02,119:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-09-06 22:55:02,119:INFO:create_model() successfully completed......................................
2024-09-06 22:55:02,298:INFO:SubProcess create_model() end ==================================
2024-09-06 22:55:02,298:INFO:Creating metrics dataframe
2024-09-06 22:55:02,307:INFO:Initializing Extra Trees Classifier
2024-09-06 22:55:02,308:INFO:Total runtime is 0.21875813802083333 minutes
2024-09-06 22:55:02,312:INFO:SubProcess create_model() called ==================================
2024-09-06 22:55:02,312:INFO:Initializing create_model()
2024-09-06 22:55:02,312:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000288D1925710>, estimator=et, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000288D1976790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-06 22:55:02,312:INFO:Checking exceptions
2024-09-06 22:55:02,312:INFO:Importing libraries
2024-09-06 22:55:02,312:INFO:Copying training dataset
2024-09-06 22:55:02,326:INFO:Defining folds
2024-09-06 22:55:02,326:INFO:Declaring metric variables
2024-09-06 22:55:02,330:INFO:Importing untrained model
2024-09-06 22:55:02,334:INFO:Extra Trees Classifier Imported successfully
2024-09-06 22:55:02,341:INFO:Starting cross validation
2024-09-06 22:55:02,342:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-09-06 22:55:03,770:INFO:Calculating mean and std
2024-09-06 22:55:03,773:INFO:Creating metrics dataframe
2024-09-06 22:55:03,776:INFO:Uploading results into container
2024-09-06 22:55:03,776:INFO:Uploading model into container now
2024-09-06 22:55:03,777:INFO:_master_model_container: 12
2024-09-06 22:55:03,777:INFO:_display_container: 2
2024-09-06 22:55:03,778:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2024-09-06 22:55:03,778:INFO:create_model() successfully completed......................................
2024-09-06 22:55:03,969:INFO:SubProcess create_model() end ==================================
2024-09-06 22:55:03,969:INFO:Creating metrics dataframe
2024-09-06 22:55:03,980:INFO:Initializing Extreme Gradient Boosting
2024-09-06 22:55:03,980:INFO:Total runtime is 0.24662371079126993 minutes
2024-09-06 22:55:03,984:INFO:SubProcess create_model() called ==================================
2024-09-06 22:55:03,984:INFO:Initializing create_model()
2024-09-06 22:55:03,984:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000288D1925710>, estimator=xgboost, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000288D1976790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-06 22:55:03,984:INFO:Checking exceptions
2024-09-06 22:55:03,984:INFO:Importing libraries
2024-09-06 22:55:03,984:INFO:Copying training dataset
2024-09-06 22:55:03,999:INFO:Defining folds
2024-09-06 22:55:03,999:INFO:Declaring metric variables
2024-09-06 22:55:04,006:INFO:Importing untrained model
2024-09-06 22:55:04,010:INFO:Extreme Gradient Boosting Imported successfully
2024-09-06 22:55:04,018:INFO:Starting cross validation
2024-09-06 22:55:04,018:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-09-06 22:55:04,548:INFO:Calculating mean and std
2024-09-06 22:55:04,549:INFO:Creating metrics dataframe
2024-09-06 22:55:04,552:INFO:Uploading results into container
2024-09-06 22:55:04,553:INFO:Uploading model into container now
2024-09-06 22:55:04,553:INFO:_master_model_container: 13
2024-09-06 22:55:04,553:INFO:_display_container: 2
2024-09-06 22:55:04,554:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-09-06 22:55:04,554:INFO:create_model() successfully completed......................................
2024-09-06 22:55:04,734:INFO:SubProcess create_model() end ==================================
2024-09-06 22:55:04,734:INFO:Creating metrics dataframe
2024-09-06 22:55:04,745:INFO:Initializing Light Gradient Boosting Machine
2024-09-06 22:55:04,745:INFO:Total runtime is 0.2593694806098938 minutes
2024-09-06 22:55:04,748:INFO:SubProcess create_model() called ==================================
2024-09-06 22:55:04,748:INFO:Initializing create_model()
2024-09-06 22:55:04,748:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000288D1925710>, estimator=lightgbm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000288D1976790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-06 22:55:04,748:INFO:Checking exceptions
2024-09-06 22:55:04,748:INFO:Importing libraries
2024-09-06 22:55:04,748:INFO:Copying training dataset
2024-09-06 22:55:04,764:INFO:Defining folds
2024-09-06 22:55:04,764:INFO:Declaring metric variables
2024-09-06 22:55:04,768:INFO:Importing untrained model
2024-09-06 22:55:04,772:INFO:Light Gradient Boosting Machine Imported successfully
2024-09-06 22:55:04,789:INFO:Starting cross validation
2024-09-06 22:55:04,791:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-09-06 22:55:05,641:INFO:Calculating mean and std
2024-09-06 22:55:05,642:INFO:Creating metrics dataframe
2024-09-06 22:55:05,646:INFO:Uploading results into container
2024-09-06 22:55:05,647:INFO:Uploading model into container now
2024-09-06 22:55:05,649:INFO:_master_model_container: 14
2024-09-06 22:55:05,649:INFO:_display_container: 2
2024-09-06 22:55:05,650:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-09-06 22:55:05,650:INFO:create_model() successfully completed......................................
2024-09-06 22:55:05,868:INFO:SubProcess create_model() end ==================================
2024-09-06 22:55:05,869:INFO:Creating metrics dataframe
2024-09-06 22:55:05,884:INFO:Initializing CatBoost Classifier
2024-09-06 22:55:05,884:INFO:Total runtime is 0.27835960388183595 minutes
2024-09-06 22:55:05,890:INFO:SubProcess create_model() called ==================================
2024-09-06 22:55:05,890:INFO:Initializing create_model()
2024-09-06 22:55:05,890:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000288D1925710>, estimator=catboost, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000288D1976790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-06 22:55:05,890:INFO:Checking exceptions
2024-09-06 22:55:05,891:INFO:Importing libraries
2024-09-06 22:55:05,891:INFO:Copying training dataset
2024-09-06 22:55:05,913:INFO:Defining folds
2024-09-06 22:55:05,913:INFO:Declaring metric variables
2024-09-06 22:55:05,918:INFO:Importing untrained model
2024-09-06 22:55:05,923:INFO:CatBoost Classifier Imported successfully
2024-09-06 22:55:05,934:INFO:Starting cross validation
2024-09-06 22:55:05,935:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-09-06 22:55:25,782:INFO:Calculating mean and std
2024-09-06 22:55:25,784:INFO:Creating metrics dataframe
2024-09-06 22:55:25,789:INFO:Uploading results into container
2024-09-06 22:55:25,791:INFO:Uploading model into container now
2024-09-06 22:55:25,792:INFO:_master_model_container: 15
2024-09-06 22:55:25,792:INFO:_display_container: 2
2024-09-06 22:55:25,792:INFO:<catboost.core.CatBoostClassifier object at 0x00000288D1C38050>
2024-09-06 22:55:25,793:INFO:create_model() successfully completed......................................
2024-09-06 22:55:26,016:INFO:SubProcess create_model() end ==================================
2024-09-06 22:55:26,016:INFO:Creating metrics dataframe
2024-09-06 22:55:26,031:INFO:Initializing Dummy Classifier
2024-09-06 22:55:26,031:INFO:Total runtime is 0.6141440153121949 minutes
2024-09-06 22:55:26,035:INFO:SubProcess create_model() called ==================================
2024-09-06 22:55:26,035:INFO:Initializing create_model()
2024-09-06 22:55:26,035:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000288D1925710>, estimator=dummy, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000288D1976790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-06 22:55:26,035:INFO:Checking exceptions
2024-09-06 22:55:26,035:INFO:Importing libraries
2024-09-06 22:55:26,035:INFO:Copying training dataset
2024-09-06 22:55:26,051:INFO:Defining folds
2024-09-06 22:55:26,051:INFO:Declaring metric variables
2024-09-06 22:55:26,057:INFO:Importing untrained model
2024-09-06 22:55:26,061:INFO:Dummy Classifier Imported successfully
2024-09-06 22:55:26,069:INFO:Starting cross validation
2024-09-06 22:55:26,070:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2024-09-06 22:55:26,135:WARNING:c:\Users\ardav\miniconda3\envs\vsc\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-06 22:55:26,152:WARNING:c:\Users\ardav\miniconda3\envs\vsc\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-06 22:55:26,153:WARNING:c:\Users\ardav\miniconda3\envs\vsc\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-06 22:55:26,158:WARNING:c:\Users\ardav\miniconda3\envs\vsc\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-06 22:55:26,227:WARNING:c:\Users\ardav\miniconda3\envs\vsc\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-06 22:55:26,238:INFO:Calculating mean and std
2024-09-06 22:55:26,239:INFO:Creating metrics dataframe
2024-09-06 22:55:26,241:INFO:Uploading results into container
2024-09-06 22:55:26,242:INFO:Uploading model into container now
2024-09-06 22:55:26,243:INFO:_master_model_container: 16
2024-09-06 22:55:26,243:INFO:_display_container: 2
2024-09-06 22:55:26,243:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2024-09-06 22:55:26,243:INFO:create_model() successfully completed......................................
2024-09-06 22:55:26,450:INFO:SubProcess create_model() end ==================================
2024-09-06 22:55:26,451:INFO:Creating metrics dataframe
2024-09-06 22:55:26,479:INFO:Initializing create_model()
2024-09-06 22:55:26,479:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000288D1925710>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-06 22:55:26,479:INFO:Checking exceptions
2024-09-06 22:55:26,482:INFO:Importing libraries
2024-09-06 22:55:26,482:INFO:Copying training dataset
2024-09-06 22:55:26,503:INFO:Defining folds
2024-09-06 22:55:26,503:INFO:Declaring metric variables
2024-09-06 22:55:26,504:INFO:Importing untrained model
2024-09-06 22:55:26,504:INFO:Declaring custom model
2024-09-06 22:55:26,504:INFO:Light Gradient Boosting Machine Imported successfully
2024-09-06 22:55:26,505:INFO:Cross validation set to False
2024-09-06 22:55:26,505:INFO:Fitting Model
2024-09-06 22:55:26,544:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-09-06 22:55:26,544:INFO:[LightGBM] [Info] Number of positive: 4390, number of negative: 13834
2024-09-06 22:55:26,547:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000916 seconds.
2024-09-06 22:55:26,547:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-09-06 22:55:26,547:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-09-06 22:55:26,547:INFO:[LightGBM] [Info] Total Bins 665
2024-09-06 22:55:26,547:INFO:[LightGBM] [Info] Number of data points in the train set: 18224, number of used features: 15
2024-09-06 22:55:26,547:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.240891 -> initscore=-1.147800
2024-09-06 22:55:26,547:INFO:[LightGBM] [Info] Start training from score -1.147800
2024-09-06 22:55:26,695:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-09-06 22:55:26,695:INFO:create_model() successfully completed......................................
2024-09-06 22:55:26,933:INFO:_master_model_container: 16
2024-09-06 22:55:26,933:INFO:_display_container: 2
2024-09-06 22:55:26,934:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-09-06 22:55:26,934:INFO:compare_models() successfully completed......................................
2024-09-06 22:55:26,936:INFO:Initializing create_model()
2024-09-06 22:55:26,936:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000288D1925710>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-06 22:55:26,936:INFO:Checking exceptions
2024-09-06 22:55:26,951:INFO:Importing libraries
2024-09-06 22:55:26,951:INFO:Copying training dataset
2024-09-06 22:55:26,975:INFO:Defining folds
2024-09-06 22:55:26,975:INFO:Declaring metric variables
2024-09-06 22:55:26,978:INFO:Importing untrained model
2024-09-06 22:55:26,979:INFO:Declaring custom model
2024-09-06 22:55:26,984:INFO:Light Gradient Boosting Machine Imported successfully
2024-09-06 22:55:26,994:INFO:Starting cross validation
2024-09-06 22:55:26,996:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-06 22:55:28,999:INFO:Calculating mean and std
2024-09-06 22:55:29,000:INFO:Creating metrics dataframe
2024-09-06 22:55:29,010:INFO:Finalizing model
2024-09-06 22:55:29,068:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-09-06 22:55:29,069:INFO:[LightGBM] [Info] Number of positive: 4390, number of negative: 13834
2024-09-06 22:55:29,072:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001105 seconds.
2024-09-06 22:55:29,072:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-09-06 22:55:29,072:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-09-06 22:55:29,073:INFO:[LightGBM] [Info] Total Bins 665
2024-09-06 22:55:29,073:INFO:[LightGBM] [Info] Number of data points in the train set: 18224, number of used features: 15
2024-09-06 22:55:29,073:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.240891 -> initscore=-1.147800
2024-09-06 22:55:29,073:INFO:[LightGBM] [Info] Start training from score -1.147800
2024-09-06 22:55:29,284:INFO:Uploading results into container
2024-09-06 22:55:29,287:INFO:Uploading model into container now
2024-09-06 22:55:29,305:INFO:_master_model_container: 17
2024-09-06 22:55:29,306:INFO:_display_container: 3
2024-09-06 22:55:29,307:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-09-06 22:55:29,307:INFO:create_model() successfully completed......................................
2024-09-06 22:55:29,520:INFO:Initializing tune_model()
2024-09-06 22:55:29,520:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000288D1925710>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=F1, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2024-09-06 22:55:29,520:INFO:Checking exceptions
2024-09-06 22:55:29,540:INFO:Copying training dataset
2024-09-06 22:55:29,554:INFO:Checking base model
2024-09-06 22:55:29,554:INFO:Base model : Light Gradient Boosting Machine
2024-09-06 22:55:29,558:INFO:Declaring metric variables
2024-09-06 22:55:29,563:INFO:Defining Hyperparameters
2024-09-06 22:55:29,761:INFO:Tuning with n_jobs=-1
2024-09-06 22:55:29,761:INFO:Initializing RandomizedSearchCV
2024-09-06 22:55:54,738:INFO:best_params: {'actual_estimator__reg_lambda': 3, 'actual_estimator__reg_alpha': 2, 'actual_estimator__num_leaves': 70, 'actual_estimator__n_estimators': 260, 'actual_estimator__min_split_gain': 0.9, 'actual_estimator__min_child_samples': 41, 'actual_estimator__learning_rate': 0.1, 'actual_estimator__feature_fraction': 0.4, 'actual_estimator__bagging_freq': 2, 'actual_estimator__bagging_fraction': 0.6}
2024-09-06 22:55:54,740:INFO:Hyperparameter search completed
2024-09-06 22:55:54,741:INFO:SubProcess create_model() called ==================================
2024-09-06 22:55:54,742:INFO:Initializing create_model()
2024-09-06 22:55:54,742:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000288D1925710>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000288D1D7D6D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 3, 'reg_alpha': 2, 'num_leaves': 70, 'n_estimators': 260, 'min_split_gain': 0.9, 'min_child_samples': 41, 'learning_rate': 0.1, 'feature_fraction': 0.4, 'bagging_freq': 2, 'bagging_fraction': 0.6})
2024-09-06 22:55:54,743:INFO:Checking exceptions
2024-09-06 22:55:54,743:INFO:Importing libraries
2024-09-06 22:55:54,743:INFO:Copying training dataset
2024-09-06 22:55:54,776:INFO:Defining folds
2024-09-06 22:55:54,777:INFO:Declaring metric variables
2024-09-06 22:55:54,783:INFO:Importing untrained model
2024-09-06 22:55:54,783:INFO:Declaring custom model
2024-09-06 22:55:54,789:INFO:Light Gradient Boosting Machine Imported successfully
2024-09-06 22:55:54,801:INFO:Starting cross validation
2024-09-06 22:55:54,803:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-06 22:55:57,435:INFO:Calculating mean and std
2024-09-06 22:55:57,437:INFO:Creating metrics dataframe
2024-09-06 22:55:57,445:INFO:Finalizing model
2024-09-06 22:55:57,488:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-09-06 22:55:57,488:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-09-06 22:55:57,488:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-09-06 22:55:57,505:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-09-06 22:55:57,506:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-09-06 22:55:57,506:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-09-06 22:55:57,506:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-09-06 22:55:57,506:INFO:[LightGBM] [Info] Number of positive: 4390, number of negative: 13834
2024-09-06 22:55:57,509:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000793 seconds.
2024-09-06 22:55:57,510:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-09-06 22:55:57,510:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-09-06 22:55:57,510:INFO:[LightGBM] [Info] Total Bins 665
2024-09-06 22:55:57,511:INFO:[LightGBM] [Info] Number of data points in the train set: 18224, number of used features: 15
2024-09-06 22:55:57,511:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.240891 -> initscore=-1.147800
2024-09-06 22:55:57,511:INFO:[LightGBM] [Info] Start training from score -1.147800
2024-09-06 22:55:57,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,518:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,522:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,525:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,527:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,537:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,557:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,559:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,600:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,617:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,624:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,647:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,649:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,651:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,655:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,660:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,665:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,669:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,672:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,676:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,679:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,681:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,683:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,685:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,687:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,689:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,691:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,692:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,694:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,695:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,696:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,697:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,699:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,700:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,703:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,707:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,708:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,715:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,722:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,723:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,725:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,726:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,729:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,733:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,736:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,738:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,741:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,745:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,751:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,756:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,759:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,761:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,763:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,765:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,768:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,770:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,772:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,773:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,774:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,777:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,782:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,785:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,787:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,788:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,790:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,792:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,793:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,793:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,795:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,797:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,799:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,801:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,802:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,803:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,804:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,808:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,808:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-09-06 22:55:57,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,812:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,815:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,817:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-09-06 22:55:57,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,824:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,827:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,828:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,829:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,830:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,832:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,834:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,834:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,835:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,835:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-09-06 22:55:57,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,837:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,839:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,845:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,848:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,850:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,851:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,863:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,863:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,863:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-09-06 22:55:57,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,864:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-09-06 22:55:57,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,868:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,870:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,881:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,885:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,887:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,891:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,892:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,893:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,894:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,895:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,896:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,898:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,899:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,901:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,902:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,904:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,905:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,908:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,909:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,910:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,912:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,913:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,914:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,915:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,916:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,917:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,917:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-09-06 22:55:57,919:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,921:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,922:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,924:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,926:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,928:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-09-06 22:55:57,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,929:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-09-06 22:55:57,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,949:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,951:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,952:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,953:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,954:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,954:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-09-06 22:55:57,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,957:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,958:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 22:55:57,978:INFO:Uploading results into container
2024-09-06 22:55:57,979:INFO:Uploading model into container now
2024-09-06 22:55:57,980:INFO:_master_model_container: 18
2024-09-06 22:55:57,980:INFO:_display_container: 4
2024-09-06 22:55:57,982:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-09-06 22:55:57,982:INFO:create_model() successfully completed......................................
2024-09-06 22:55:58,193:INFO:SubProcess create_model() end ==================================
2024-09-06 22:55:58,194:INFO:choose_better activated
2024-09-06 22:55:58,197:INFO:SubProcess create_model() called ==================================
2024-09-06 22:55:58,198:INFO:Initializing create_model()
2024-09-06 22:55:58,198:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000288D1925710>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-06 22:55:58,198:INFO:Checking exceptions
2024-09-06 22:55:58,200:INFO:Importing libraries
2024-09-06 22:55:58,200:INFO:Copying training dataset
2024-09-06 22:55:58,215:INFO:Defining folds
2024-09-06 22:55:58,215:INFO:Declaring metric variables
2024-09-06 22:55:58,216:INFO:Importing untrained model
2024-09-06 22:55:58,216:INFO:Declaring custom model
2024-09-06 22:55:58,216:INFO:Light Gradient Boosting Machine Imported successfully
2024-09-06 22:55:58,216:INFO:Starting cross validation
2024-09-06 22:55:58,217:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-06 22:56:00,119:INFO:Calculating mean and std
2024-09-06 22:56:00,120:INFO:Creating metrics dataframe
2024-09-06 22:56:00,122:INFO:Finalizing model
2024-09-06 22:56:00,171:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-09-06 22:56:00,172:INFO:[LightGBM] [Info] Number of positive: 4390, number of negative: 13834
2024-09-06 22:56:00,174:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000982 seconds.
2024-09-06 22:56:00,175:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-09-06 22:56:00,175:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-09-06 22:56:00,175:INFO:[LightGBM] [Info] Total Bins 665
2024-09-06 22:56:00,175:INFO:[LightGBM] [Info] Number of data points in the train set: 18224, number of used features: 15
2024-09-06 22:56:00,175:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.240891 -> initscore=-1.147800
2024-09-06 22:56:00,175:INFO:[LightGBM] [Info] Start training from score -1.147800
2024-09-06 22:56:00,386:INFO:Uploading results into container
2024-09-06 22:56:00,387:INFO:Uploading model into container now
2024-09-06 22:56:00,388:INFO:_master_model_container: 19
2024-09-06 22:56:00,388:INFO:_display_container: 5
2024-09-06 22:56:00,389:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-09-06 22:56:00,389:INFO:create_model() successfully completed......................................
2024-09-06 22:56:00,625:INFO:SubProcess create_model() end ==================================
2024-09-06 22:56:00,626:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for F1 is 0.6982
2024-09-06 22:56:00,627:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for F1 is 0.6971
2024-09-06 22:56:00,627:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2024-09-06 22:56:00,627:INFO:choose_better completed
2024-09-06 22:56:00,627:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2024-09-06 22:56:00,640:INFO:_master_model_container: 19
2024-09-06 22:56:00,640:INFO:_display_container: 4
2024-09-06 22:56:00,641:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-09-06 22:56:00,641:INFO:tune_model() successfully completed......................................
2024-09-06 22:56:00,846:INFO:Initializing finalize_model()
2024-09-06 22:56:00,846:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000288D1925710>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-09-06 22:56:00,847:INFO:Finalizing LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-09-06 22:56:00,854:INFO:Initializing create_model()
2024-09-06 22:56:00,855:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000288D1925710>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-09-06 22:56:00,855:INFO:Checking exceptions
2024-09-06 22:56:00,856:INFO:Importing libraries
2024-09-06 22:56:00,856:INFO:Copying training dataset
2024-09-06 22:56:00,857:INFO:Defining folds
2024-09-06 22:56:00,857:INFO:Declaring metric variables
2024-09-06 22:56:00,857:INFO:Importing untrained model
2024-09-06 22:56:00,857:INFO:Declaring custom model
2024-09-06 22:56:00,858:INFO:Light Gradient Boosting Machine Imported successfully
2024-09-06 22:56:00,858:INFO:Cross validation set to False
2024-09-06 22:56:00,859:INFO:Fitting Model
2024-09-06 22:56:00,900:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-09-06 22:56:00,901:INFO:[LightGBM] [Info] Number of positive: 6272, number of negative: 19763
2024-09-06 22:56:00,904:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001292 seconds.
2024-09-06 22:56:00,904:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-09-06 22:56:00,905:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-09-06 22:56:00,905:INFO:[LightGBM] [Info] Total Bins 681
2024-09-06 22:56:00,905:INFO:[LightGBM] [Info] Number of data points in the train set: 26035, number of used features: 15
2024-09-06 22:56:00,905:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.240906 -> initscore=-1.147716
2024-09-06 22:56:00,905:INFO:[LightGBM] [Info] Start training from score -1.147716
2024-09-06 22:56:01,086:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Tahun Kelahiran',
                                             'Kelas Pekerjaan', 'fnlwgt',
                                             'Pendidikan', 'Jenjang Pendidikan',
                                             'Status', 'Pekerjaan', 'Hubungan',
                                             'Etnis', 'sex', 'pendapatan',
                                             'pengeluaran', 'hours per week',
                                             'Asal Negara', 'jumlah_anak'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-09-06 22:56:01,086:INFO:create_model() successfully completed......................................
2024-09-06 22:56:01,300:INFO:_master_model_container: 19
2024-09-06 22:56:01,300:INFO:_display_container: 4
2024-09-06 22:56:01,306:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Tahun Kelahiran',
                                             'Kelas Pekerjaan', 'fnlwgt',
                                             'Pendidikan', 'Jenjang Pendidikan',
                                             'Status', 'Pekerjaan', 'Hubungan',
                                             'Etnis', 'sex', 'pendapatan',
                                             'pengeluaran', 'hours per week',
                                             'Asal Negara', 'jumlah_anak'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-09-06 22:56:01,306:INFO:finalize_model() successfully completed......................................
2024-09-06 22:56:21,506:INFO:Initializing predict_model()
2024-09-06 22:56:21,507:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000288D1925710>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Tahun Kelahiran',
                                             'Kelas Pekerjaan', 'fnlwgt',
                                             'Pendidikan', 'Jenjang Pendidikan',
                                             'Status', 'Pekerjaan', 'Hubungan',
                                             'Etnis', 'sex', 'pendapatan',
                                             'pengeluaran', 'hours per week',
                                             'Asal Negara', 'jumlah_anak'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000288D2EBE980>)
2024-09-06 22:56:21,507:INFO:Checking exceptions
2024-09-06 22:56:21,507:INFO:Preloading libraries
2024-09-06 22:56:21,510:INFO:Set up data.
2024-09-06 22:56:21,527:INFO:Set up index.
2024-09-06 22:56:44,564:INFO:Initializing predict_model()
2024-09-06 22:56:44,564:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000288D1925710>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Tahun Kelahiran',
                                             'Kelas Pekerjaan', 'fnlwgt',
                                             'Pendidikan', 'Jenjang Pendidikan',
                                             'Status', 'Pekerjaan', 'Hubungan',
                                             'Etnis', 'sex', 'pendapatan',
                                             'pengeluaran', 'hours per week',
                                             'Asal Negara', 'jumlah_anak'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000288D4A16520>)
2024-09-06 22:56:44,564:INFO:Checking exceptions
2024-09-06 22:56:44,564:INFO:Preloading libraries
2024-09-06 22:56:44,567:INFO:Set up data.
2024-09-06 22:56:44,586:INFO:Set up index.
2024-09-06 22:57:51,844:INFO:Initializing predict_model()
2024-09-06 22:57:51,844:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000288D1925710>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Tahun Kelahiran',
                                             'Kelas Pekerjaan', 'fnlwgt',
                                             'Pendidikan', 'Jenjang Pendidikan',
                                             'Status', 'Pekerjaan', 'Hubungan',
                                             'Etnis', 'sex', 'pendapatan',
                                             'pengeluaran', 'hours per week',
                                             'Asal Negara', 'jumlah_anak'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000288D4E73E20>)
2024-09-06 22:57:51,844:INFO:Checking exceptions
2024-09-06 22:57:51,844:INFO:Preloading libraries
2024-09-06 22:57:51,848:INFO:Set up data.
2024-09-06 22:57:51,854:INFO:Set up index.
2024-09-06 22:59:41,908:INFO:PyCaret ClassificationExperiment
2024-09-06 22:59:41,908:INFO:Logging name: clf-default-name
2024-09-06 22:59:41,909:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-09-06 22:59:41,909:INFO:version 3.3.2
2024-09-06 22:59:41,909:INFO:Initializing setup()
2024-09-06 22:59:41,909:INFO:self.USI: 5160
2024-09-06 22:59:41,909:INFO:self._variable_keys: {'idx', 'y', 'y_train', 'seed', 'USI', 'memory', 'fix_imbalance', 'exp_id', 'exp_name_log', 'data', 'is_multiclass', '_available_plots', 'html_param', 'X_train', 'log_plots_param', 'fold_generator', 'X_test', 'y_test', 'n_jobs_param', 'X', 'gpu_param', 'pipeline', 'fold_groups_param', 'fold_shuffle_param', '_ml_usecase', 'target_param', 'gpu_n_jobs_param', 'logging_param'}
2024-09-06 22:59:41,909:INFO:Checking environment
2024-09-06 22:59:41,909:INFO:python_version: 3.11.9
2024-09-06 22:59:41,909:INFO:python_build: ('main', 'Apr 19 2024 16:40:41')
2024-09-06 22:59:41,909:INFO:machine: AMD64
2024-09-06 22:59:41,909:INFO:platform: Windows-10-10.0.22631-SP0
2024-09-06 22:59:41,915:INFO:Memory: svmem(total=16867028992, available=1314136064, percent=92.2, used=15552892928, free=1314136064)
2024-09-06 22:59:41,915:INFO:Physical Core: 6
2024-09-06 22:59:41,915:INFO:Logical Core: 12
2024-09-06 22:59:41,915:INFO:Checking libraries
2024-09-06 22:59:41,915:INFO:System:
2024-09-06 22:59:41,915:INFO:    python: 3.11.9 | packaged by Anaconda, Inc. | (main, Apr 19 2024, 16:40:41) [MSC v.1916 64 bit (AMD64)]
2024-09-06 22:59:41,915:INFO:executable: c:\Users\ardav\miniconda3\envs\vsc\python.exe
2024-09-06 22:59:41,915:INFO:   machine: Windows-10-10.0.22631-SP0
2024-09-06 22:59:41,915:INFO:PyCaret required dependencies:
2024-09-06 22:59:41,915:INFO:                 pip: 23.2.1
2024-09-06 22:59:41,915:INFO:          setuptools: 67.8.0
2024-09-06 22:59:41,916:INFO:             pycaret: 3.3.2
2024-09-06 22:59:41,916:INFO:             IPython: 8.14.0
2024-09-06 22:59:41,916:INFO:          ipywidgets: 8.1.5
2024-09-06 22:59:41,916:INFO:                tqdm: 4.66.5
2024-09-06 22:59:41,916:INFO:               numpy: 1.26.4
2024-09-06 22:59:41,916:INFO:              pandas: 2.0.3
2024-09-06 22:59:41,916:INFO:              jinja2: 3.1.4
2024-09-06 22:59:41,916:INFO:               scipy: 1.10.1
2024-09-06 22:59:41,916:INFO:              joblib: 1.2.0
2024-09-06 22:59:41,916:INFO:             sklearn: 1.4.2
2024-09-06 22:59:41,916:INFO:                pyod: 2.0.1
2024-09-06 22:59:41,916:INFO:            imblearn: 0.12.3
2024-09-06 22:59:41,916:INFO:   category_encoders: 2.6.3
2024-09-06 22:59:41,916:INFO:            lightgbm: 4.5.0
2024-09-06 22:59:41,916:INFO:               numba: 0.60.0
2024-09-06 22:59:41,916:INFO:            requests: 2.32.3
2024-09-06 22:59:41,916:INFO:          matplotlib: 3.7.1
2024-09-06 22:59:41,916:INFO:          scikitplot: 0.3.7
2024-09-06 22:59:41,916:INFO:         yellowbrick: 1.5
2024-09-06 22:59:41,916:INFO:              plotly: 5.16.1
2024-09-06 22:59:41,916:INFO:    plotly-resampler: Not installed
2024-09-06 22:59:41,916:INFO:             kaleido: 0.2.1
2024-09-06 22:59:41,917:INFO:           schemdraw: 0.15
2024-09-06 22:59:41,917:INFO:         statsmodels: 0.14.2
2024-09-06 22:59:41,917:INFO:              sktime: 0.26.0
2024-09-06 22:59:41,917:INFO:               tbats: 1.1.3
2024-09-06 22:59:41,917:INFO:            pmdarima: 2.0.4
2024-09-06 22:59:41,917:INFO:              psutil: 5.9.0
2024-09-06 22:59:41,917:INFO:          markupsafe: 2.1.3
2024-09-06 22:59:41,917:INFO:             pickle5: Not installed
2024-09-06 22:59:41,917:INFO:         cloudpickle: 3.0.0
2024-09-06 22:59:41,917:INFO:         deprecation: 2.1.0
2024-09-06 22:59:41,917:INFO:              xxhash: 3.5.0
2024-09-06 22:59:41,917:INFO:           wurlitzer: Not installed
2024-09-06 22:59:41,917:INFO:PyCaret optional dependencies:
2024-09-06 22:59:41,917:INFO:                shap: Not installed
2024-09-06 22:59:41,917:INFO:           interpret: Not installed
2024-09-06 22:59:41,917:INFO:                umap: Not installed
2024-09-06 22:59:41,917:INFO:     ydata_profiling: Not installed
2024-09-06 22:59:41,917:INFO:  explainerdashboard: Not installed
2024-09-06 22:59:41,917:INFO:             autoviz: Not installed
2024-09-06 22:59:41,917:INFO:           fairlearn: Not installed
2024-09-06 22:59:41,917:INFO:          deepchecks: Not installed
2024-09-06 22:59:41,918:INFO:             xgboost: 2.1.1
2024-09-06 22:59:41,918:INFO:            catboost: 1.2.5
2024-09-06 22:59:41,918:INFO:              kmodes: Not installed
2024-09-06 22:59:41,918:INFO:             mlxtend: Not installed
2024-09-06 22:59:41,918:INFO:       statsforecast: Not installed
2024-09-06 22:59:41,918:INFO:        tune_sklearn: Not installed
2024-09-06 22:59:41,918:INFO:                 ray: Not installed
2024-09-06 22:59:41,918:INFO:            hyperopt: Not installed
2024-09-06 22:59:41,918:INFO:              optuna: 4.0.0
2024-09-06 22:59:41,918:INFO:               skopt: Not installed
2024-09-06 22:59:41,918:INFO:              mlflow: Not installed
2024-09-06 22:59:41,918:INFO:              gradio: 4.41.0
2024-09-06 22:59:41,918:INFO:             fastapi: 0.112.1
2024-09-06 22:59:41,918:INFO:             uvicorn: 0.30.6
2024-09-06 22:59:41,918:INFO:              m2cgen: Not installed
2024-09-06 22:59:41,918:INFO:           evidently: Not installed
2024-09-06 22:59:41,918:INFO:               fugue: Not installed
2024-09-06 22:59:41,918:INFO:           streamlit: 1.38.0
2024-09-06 22:59:41,918:INFO:             prophet: Not installed
2024-09-06 22:59:41,918:INFO:None
2024-09-06 22:59:41,918:INFO:Set up data.
2024-09-06 22:59:41,935:INFO:Set up folding strategy.
2024-09-06 22:59:41,935:INFO:Set up train/test split.
2024-09-06 22:59:41,951:INFO:Set up index.
2024-09-06 22:59:41,952:INFO:Assigning column types.
2024-09-06 22:59:41,961:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-09-06 22:59:42,006:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-09-06 22:59:42,006:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-09-06 22:59:42,034:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-06 22:59:42,036:INFO:Soft dependency imported: catboost: 1.2.5
2024-09-06 22:59:42,077:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-09-06 22:59:42,078:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-09-06 22:59:42,103:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-06 22:59:42,106:INFO:Soft dependency imported: catboost: 1.2.5
2024-09-06 22:59:42,107:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-09-06 22:59:42,149:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-09-06 22:59:42,174:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-06 22:59:42,176:INFO:Soft dependency imported: catboost: 1.2.5
2024-09-06 22:59:42,227:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-09-06 22:59:42,257:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-06 22:59:42,259:INFO:Soft dependency imported: catboost: 1.2.5
2024-09-06 22:59:42,260:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-09-06 22:59:42,324:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-06 22:59:42,327:INFO:Soft dependency imported: catboost: 1.2.5
2024-09-06 22:59:42,395:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-06 22:59:42,398:INFO:Soft dependency imported: catboost: 1.2.5
2024-09-06 22:59:42,400:INFO:Preparing preprocessing pipeline...
2024-09-06 22:59:42,401:INFO:Set up simple imputation.
2024-09-06 22:59:42,402:INFO:Set up imbalanced handling.
2024-09-06 22:59:42,403:INFO:Set up column name cleaning.
2024-09-06 22:59:42,525:INFO:Finished creating preprocessing pipeline.
2024-09-06 22:59:42,530:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\ardav\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Tahun Kelahiran',
                                             'Kelas Pekerjaan', 'fnlwgt',
                                             'Pendidikan', 'Jenjang Pendidikan',
                                             'Status', 'Pekerjaan', 'Hubungan',
                                             'Etnis', 'sex', 'pendapatan',
                                             'pengeluaran', 'hours per week',
                                             'Asal Negara', 'jumlah_anak'],
                                    transformer...
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=123,
                                                                              sampling_strategy='auto')))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2024-09-06 22:59:42,530:INFO:Creating final display dataframe.
2024-09-06 22:59:42,817:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target            income
2                   Target type            Binary
3           Original data shape       (26035, 16)
4        Transformed data shape       (35479, 16)
5   Transformed train set shape       (27668, 16)
6    Transformed test set shape        (7811, 16)
7              Numeric features                15
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12                Fix imbalance              True
13         Fix imbalance method             smote
14               Fold Generator   StratifiedKFold
15                  Fold Number                10
16                     CPU Jobs                -1
17                      Use GPU             False
18               Log Experiment             False
19              Experiment Name  clf-default-name
20                          USI              5160
2024-09-06 22:59:42,900:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-06 22:59:42,902:INFO:Soft dependency imported: catboost: 1.2.5
2024-09-06 22:59:42,981:INFO:Soft dependency imported: xgboost: 2.1.1
2024-09-06 22:59:42,984:INFO:Soft dependency imported: catboost: 1.2.5
2024-09-06 22:59:42,986:INFO:setup() successfully completed in 1.08s...............
2024-09-06 22:59:42,987:INFO:Initializing compare_models()
2024-09-06 22:59:42,987:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000288D4363110>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x00000288D4363110>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2024-09-06 22:59:42,987:INFO:Checking exceptions
2024-09-06 22:59:42,996:INFO:Preparing display monitor
2024-09-06 22:59:43,019:INFO:Initializing Logistic Regression
2024-09-06 22:59:43,019:INFO:Total runtime is 8.718172709147136e-06 minutes
2024-09-06 22:59:43,025:INFO:SubProcess create_model() called ==================================
2024-09-06 22:59:43,026:INFO:Initializing create_model()
2024-09-06 22:59:43,026:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000288D4363110>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000288D51F55D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-06 22:59:43,026:INFO:Checking exceptions
2024-09-06 22:59:43,026:INFO:Importing libraries
2024-09-06 22:59:43,026:INFO:Copying training dataset
2024-09-06 22:59:43,051:INFO:Defining folds
2024-09-06 22:59:43,051:INFO:Declaring metric variables
2024-09-06 22:59:43,057:INFO:Importing untrained model
2024-09-06 22:59:43,066:INFO:Logistic Regression Imported successfully
2024-09-06 22:59:43,079:INFO:Starting cross validation
2024-09-06 22:59:43,082:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-06 22:59:48,240:WARNING:c:\Users\ardav\miniconda3\envs\vsc\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-09-06 22:59:49,024:WARNING:c:\Users\ardav\miniconda3\envs\vsc\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-09-06 22:59:49,116:WARNING:c:\Users\ardav\miniconda3\envs\vsc\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-09-06 22:59:49,404:WARNING:c:\Users\ardav\miniconda3\envs\vsc\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-09-06 22:59:49,526:WARNING:c:\Users\ardav\miniconda3\envs\vsc\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-09-06 22:59:49,532:WARNING:c:\Users\ardav\miniconda3\envs\vsc\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-09-06 22:59:49,535:WARNING:c:\Users\ardav\miniconda3\envs\vsc\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-09-06 22:59:49,581:WARNING:c:\Users\ardav\miniconda3\envs\vsc\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-09-06 22:59:49,598:WARNING:c:\Users\ardav\miniconda3\envs\vsc\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-09-06 22:59:49,777:WARNING:c:\Users\ardav\miniconda3\envs\vsc\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-09-06 22:59:49,804:INFO:Calculating mean and std
2024-09-06 22:59:49,806:INFO:Creating metrics dataframe
2024-09-06 22:59:49,808:INFO:Uploading results into container
2024-09-06 22:59:49,809:INFO:Uploading model into container now
2024-09-06 22:59:49,809:INFO:_master_model_container: 1
2024-09-06 22:59:49,809:INFO:_display_container: 2
2024-09-06 22:59:49,810:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-09-06 22:59:49,810:INFO:create_model() successfully completed......................................
2024-09-06 22:59:50,031:INFO:SubProcess create_model() end ==================================
2024-09-06 22:59:50,032:INFO:Creating metrics dataframe
2024-09-06 22:59:50,040:INFO:Initializing K Neighbors Classifier
2024-09-06 22:59:50,040:INFO:Total runtime is 0.11702701648076375 minutes
2024-09-06 22:59:50,045:INFO:SubProcess create_model() called ==================================
2024-09-06 22:59:50,045:INFO:Initializing create_model()
2024-09-06 22:59:50,045:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000288D4363110>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000288D51F55D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-06 22:59:50,045:INFO:Checking exceptions
2024-09-06 22:59:50,045:INFO:Importing libraries
2024-09-06 22:59:50,045:INFO:Copying training dataset
2024-09-06 22:59:50,064:INFO:Defining folds
2024-09-06 22:59:50,064:INFO:Declaring metric variables
2024-09-06 22:59:50,068:INFO:Importing untrained model
2024-09-06 22:59:50,074:INFO:K Neighbors Classifier Imported successfully
2024-09-06 22:59:50,086:INFO:Starting cross validation
2024-09-06 22:59:50,089:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-06 22:59:50,836:INFO:Calculating mean and std
2024-09-06 22:59:50,838:INFO:Creating metrics dataframe
2024-09-06 22:59:50,842:INFO:Uploading results into container
2024-09-06 22:59:50,843:INFO:Uploading model into container now
2024-09-06 22:59:50,844:INFO:_master_model_container: 2
2024-09-06 22:59:50,844:INFO:_display_container: 2
2024-09-06 22:59:50,844:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-09-06 22:59:50,845:INFO:create_model() successfully completed......................................
2024-09-06 22:59:51,051:INFO:SubProcess create_model() end ==================================
2024-09-06 22:59:51,051:INFO:Creating metrics dataframe
2024-09-06 22:59:51,060:INFO:Initializing Naive Bayes
2024-09-06 22:59:51,060:INFO:Total runtime is 0.13401683171590167 minutes
2024-09-06 22:59:51,064:INFO:SubProcess create_model() called ==================================
2024-09-06 22:59:51,065:INFO:Initializing create_model()
2024-09-06 22:59:51,065:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000288D4363110>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000288D51F55D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-06 22:59:51,065:INFO:Checking exceptions
2024-09-06 22:59:51,065:INFO:Importing libraries
2024-09-06 22:59:51,065:INFO:Copying training dataset
2024-09-06 22:59:51,084:INFO:Defining folds
2024-09-06 22:59:51,085:INFO:Declaring metric variables
2024-09-06 22:59:51,089:INFO:Importing untrained model
2024-09-06 22:59:51,093:INFO:Naive Bayes Imported successfully
2024-09-06 22:59:51,101:INFO:Starting cross validation
2024-09-06 22:59:51,102:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-06 22:59:51,447:INFO:Calculating mean and std
2024-09-06 22:59:51,449:INFO:Creating metrics dataframe
2024-09-06 22:59:51,452:INFO:Uploading results into container
2024-09-06 22:59:51,453:INFO:Uploading model into container now
2024-09-06 22:59:51,454:INFO:_master_model_container: 3
2024-09-06 22:59:51,454:INFO:_display_container: 2
2024-09-06 22:59:51,454:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-09-06 22:59:51,455:INFO:create_model() successfully completed......................................
2024-09-06 22:59:51,686:INFO:SubProcess create_model() end ==================================
2024-09-06 22:59:51,686:INFO:Creating metrics dataframe
2024-09-06 22:59:51,697:INFO:Initializing Decision Tree Classifier
2024-09-06 22:59:51,697:INFO:Total runtime is 0.14463930130004882 minutes
2024-09-06 22:59:51,702:INFO:SubProcess create_model() called ==================================
2024-09-06 22:59:51,703:INFO:Initializing create_model()
2024-09-06 22:59:51,703:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000288D4363110>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000288D51F55D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-06 22:59:51,703:INFO:Checking exceptions
2024-09-06 22:59:51,703:INFO:Importing libraries
2024-09-06 22:59:51,703:INFO:Copying training dataset
2024-09-06 22:59:51,725:INFO:Defining folds
2024-09-06 22:59:51,726:INFO:Declaring metric variables
2024-09-06 22:59:51,731:INFO:Importing untrained model
2024-09-06 22:59:51,736:INFO:Decision Tree Classifier Imported successfully
2024-09-06 22:59:51,747:INFO:Starting cross validation
2024-09-06 22:59:51,750:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-06 22:59:52,470:INFO:Calculating mean and std
2024-09-06 22:59:52,471:INFO:Creating metrics dataframe
2024-09-06 22:59:52,474:INFO:Uploading results into container
2024-09-06 22:59:52,474:INFO:Uploading model into container now
2024-09-06 22:59:52,475:INFO:_master_model_container: 4
2024-09-06 22:59:52,476:INFO:_display_container: 2
2024-09-06 22:59:52,477:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2024-09-06 22:59:52,477:INFO:create_model() successfully completed......................................
2024-09-06 22:59:52,684:INFO:SubProcess create_model() end ==================================
2024-09-06 22:59:52,685:INFO:Creating metrics dataframe
2024-09-06 22:59:52,693:INFO:Initializing SVM - Linear Kernel
2024-09-06 22:59:52,693:INFO:Total runtime is 0.16124175389607748 minutes
2024-09-06 22:59:52,696:INFO:SubProcess create_model() called ==================================
2024-09-06 22:59:52,697:INFO:Initializing create_model()
2024-09-06 22:59:52,697:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000288D4363110>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000288D51F55D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-06 22:59:52,697:INFO:Checking exceptions
2024-09-06 22:59:52,697:INFO:Importing libraries
2024-09-06 22:59:52,697:INFO:Copying training dataset
2024-09-06 22:59:52,713:INFO:Defining folds
2024-09-06 22:59:52,714:INFO:Declaring metric variables
2024-09-06 22:59:52,719:INFO:Importing untrained model
2024-09-06 22:59:52,724:INFO:SVM - Linear Kernel Imported successfully
2024-09-06 22:59:52,732:INFO:Starting cross validation
2024-09-06 22:59:52,733:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-06 22:59:54,894:INFO:Calculating mean and std
2024-09-06 22:59:54,895:INFO:Creating metrics dataframe
2024-09-06 22:59:54,896:INFO:Uploading results into container
2024-09-06 22:59:54,897:INFO:Uploading model into container now
2024-09-06 22:59:54,897:INFO:_master_model_container: 5
2024-09-06 22:59:54,898:INFO:_display_container: 2
2024-09-06 22:59:54,898:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-09-06 22:59:54,898:INFO:create_model() successfully completed......................................
2024-09-06 22:59:55,105:INFO:SubProcess create_model() end ==================================
2024-09-06 22:59:55,106:INFO:Creating metrics dataframe
2024-09-06 22:59:55,115:INFO:Initializing Ridge Classifier
2024-09-06 22:59:55,116:INFO:Total runtime is 0.20161314010620118 minutes
2024-09-06 22:59:55,120:INFO:SubProcess create_model() called ==================================
2024-09-06 22:59:55,120:INFO:Initializing create_model()
2024-09-06 22:59:55,121:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000288D4363110>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000288D51F55D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-06 22:59:55,121:INFO:Checking exceptions
2024-09-06 22:59:55,121:INFO:Importing libraries
2024-09-06 22:59:55,121:INFO:Copying training dataset
2024-09-06 22:59:55,136:INFO:Defining folds
2024-09-06 22:59:55,136:INFO:Declaring metric variables
2024-09-06 22:59:55,151:INFO:Importing untrained model
2024-09-06 22:59:55,157:INFO:Ridge Classifier Imported successfully
2024-09-06 22:59:55,168:INFO:Starting cross validation
2024-09-06 22:59:55,171:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-06 22:59:55,546:INFO:Calculating mean and std
2024-09-06 22:59:55,548:INFO:Creating metrics dataframe
2024-09-06 22:59:55,551:INFO:Uploading results into container
2024-09-06 22:59:55,551:INFO:Uploading model into container now
2024-09-06 22:59:55,552:INFO:_master_model_container: 6
2024-09-06 22:59:55,552:INFO:_display_container: 2
2024-09-06 22:59:55,553:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2024-09-06 22:59:55,553:INFO:create_model() successfully completed......................................
2024-09-06 22:59:55,763:INFO:SubProcess create_model() end ==================================
2024-09-06 22:59:55,763:INFO:Creating metrics dataframe
2024-09-06 22:59:55,773:INFO:Initializing Random Forest Classifier
2024-09-06 22:59:55,773:INFO:Total runtime is 0.2125647306442261 minutes
2024-09-06 22:59:55,777:INFO:SubProcess create_model() called ==================================
2024-09-06 22:59:55,777:INFO:Initializing create_model()
2024-09-06 22:59:55,777:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000288D4363110>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000288D51F55D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-06 22:59:55,777:INFO:Checking exceptions
2024-09-06 22:59:55,777:INFO:Importing libraries
2024-09-06 22:59:55,777:INFO:Copying training dataset
2024-09-06 22:59:55,794:INFO:Defining folds
2024-09-06 22:59:55,794:INFO:Declaring metric variables
2024-09-06 22:59:55,797:INFO:Importing untrained model
2024-09-06 22:59:55,803:INFO:Random Forest Classifier Imported successfully
2024-09-06 22:59:55,813:INFO:Starting cross validation
2024-09-06 22:59:55,816:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-06 23:00:03,869:INFO:Calculating mean and std
2024-09-06 23:00:03,872:INFO:Creating metrics dataframe
2024-09-06 23:00:03,874:INFO:Uploading results into container
2024-09-06 23:00:03,875:INFO:Uploading model into container now
2024-09-06 23:00:03,876:INFO:_master_model_container: 7
2024-09-06 23:00:03,876:INFO:_display_container: 2
2024-09-06 23:00:03,877:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2024-09-06 23:00:03,877:INFO:create_model() successfully completed......................................
2024-09-06 23:00:04,141:INFO:SubProcess create_model() end ==================================
2024-09-06 23:00:04,142:INFO:Creating metrics dataframe
2024-09-06 23:00:04,156:INFO:Initializing Quadratic Discriminant Analysis
2024-09-06 23:00:04,156:INFO:Total runtime is 0.3522865732510885 minutes
2024-09-06 23:00:04,163:INFO:SubProcess create_model() called ==================================
2024-09-06 23:00:04,163:INFO:Initializing create_model()
2024-09-06 23:00:04,164:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000288D4363110>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000288D51F55D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-06 23:00:04,165:INFO:Checking exceptions
2024-09-06 23:00:04,165:INFO:Importing libraries
2024-09-06 23:00:04,165:INFO:Copying training dataset
2024-09-06 23:00:04,190:INFO:Defining folds
2024-09-06 23:00:04,190:INFO:Declaring metric variables
2024-09-06 23:00:04,201:INFO:Importing untrained model
2024-09-06 23:00:04,206:INFO:Quadratic Discriminant Analysis Imported successfully
2024-09-06 23:00:04,221:INFO:Starting cross validation
2024-09-06 23:00:04,224:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-06 23:00:05,023:INFO:Calculating mean and std
2024-09-06 23:00:05,027:INFO:Creating metrics dataframe
2024-09-06 23:00:05,036:INFO:Uploading results into container
2024-09-06 23:00:05,038:INFO:Uploading model into container now
2024-09-06 23:00:05,040:INFO:_master_model_container: 8
2024-09-06 23:00:05,040:INFO:_display_container: 2
2024-09-06 23:00:05,041:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-09-06 23:00:05,041:INFO:create_model() successfully completed......................................
2024-09-06 23:00:05,321:INFO:SubProcess create_model() end ==================================
2024-09-06 23:00:05,321:INFO:Creating metrics dataframe
2024-09-06 23:00:05,333:INFO:Initializing Ada Boost Classifier
2024-09-06 23:00:05,333:INFO:Total runtime is 0.3719054142634074 minutes
2024-09-06 23:00:05,337:INFO:SubProcess create_model() called ==================================
2024-09-06 23:00:05,338:INFO:Initializing create_model()
2024-09-06 23:00:05,338:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000288D4363110>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000288D51F55D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-06 23:00:05,339:INFO:Checking exceptions
2024-09-06 23:00:05,339:INFO:Importing libraries
2024-09-06 23:00:05,339:INFO:Copying training dataset
2024-09-06 23:00:05,361:INFO:Defining folds
2024-09-06 23:00:05,362:INFO:Declaring metric variables
2024-09-06 23:00:05,370:INFO:Importing untrained model
2024-09-06 23:00:05,376:INFO:Ada Boost Classifier Imported successfully
2024-09-06 23:00:05,389:INFO:Starting cross validation
2024-09-06 23:00:05,391:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-06 23:00:05,672:WARNING:c:\Users\ardav\miniconda3\envs\vsc\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-06 23:00:05,724:WARNING:c:\Users\ardav\miniconda3\envs\vsc\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-06 23:00:05,729:WARNING:c:\Users\ardav\miniconda3\envs\vsc\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-06 23:00:05,742:WARNING:c:\Users\ardav\miniconda3\envs\vsc\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-06 23:00:05,752:WARNING:c:\Users\ardav\miniconda3\envs\vsc\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-06 23:00:05,754:WARNING:c:\Users\ardav\miniconda3\envs\vsc\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-06 23:00:05,838:WARNING:c:\Users\ardav\miniconda3\envs\vsc\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-06 23:00:05,861:WARNING:c:\Users\ardav\miniconda3\envs\vsc\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-06 23:00:05,863:WARNING:c:\Users\ardav\miniconda3\envs\vsc\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-06 23:00:05,926:WARNING:c:\Users\ardav\miniconda3\envs\vsc\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-09-06 23:00:08,519:INFO:Calculating mean and std
2024-09-06 23:00:08,520:INFO:Creating metrics dataframe
2024-09-06 23:00:08,523:INFO:Uploading results into container
2024-09-06 23:00:08,524:INFO:Uploading model into container now
2024-09-06 23:00:08,525:INFO:_master_model_container: 9
2024-09-06 23:00:08,525:INFO:_display_container: 2
2024-09-06 23:00:08,526:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2024-09-06 23:00:08,526:INFO:create_model() successfully completed......................................
2024-09-06 23:00:08,727:INFO:SubProcess create_model() end ==================================
2024-09-06 23:00:08,727:INFO:Creating metrics dataframe
2024-09-06 23:00:08,737:INFO:Initializing Gradient Boosting Classifier
2024-09-06 23:00:08,738:INFO:Total runtime is 0.42864605188369753 minutes
2024-09-06 23:00:08,743:INFO:SubProcess create_model() called ==================================
2024-09-06 23:00:08,743:INFO:Initializing create_model()
2024-09-06 23:00:08,743:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000288D4363110>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000288D51F55D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-06 23:00:08,743:INFO:Checking exceptions
2024-09-06 23:00:08,744:INFO:Importing libraries
2024-09-06 23:00:08,744:INFO:Copying training dataset
2024-09-06 23:00:08,761:INFO:Defining folds
2024-09-06 23:00:08,761:INFO:Declaring metric variables
2024-09-06 23:00:08,764:INFO:Importing untrained model
2024-09-06 23:00:08,770:INFO:Gradient Boosting Classifier Imported successfully
2024-09-06 23:00:08,780:INFO:Starting cross validation
2024-09-06 23:00:08,781:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-06 23:00:21,281:INFO:Calculating mean and std
2024-09-06 23:00:21,283:INFO:Creating metrics dataframe
2024-09-06 23:00:21,287:INFO:Uploading results into container
2024-09-06 23:00:21,288:INFO:Uploading model into container now
2024-09-06 23:00:21,289:INFO:_master_model_container: 10
2024-09-06 23:00:21,289:INFO:_display_container: 2
2024-09-06 23:00:21,291:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-09-06 23:00:21,291:INFO:create_model() successfully completed......................................
2024-09-06 23:00:21,513:INFO:SubProcess create_model() end ==================================
2024-09-06 23:00:21,514:INFO:Creating metrics dataframe
2024-09-06 23:00:21,528:INFO:Initializing Linear Discriminant Analysis
2024-09-06 23:00:21,528:INFO:Total runtime is 0.6418244520823161 minutes
2024-09-06 23:00:21,535:INFO:SubProcess create_model() called ==================================
2024-09-06 23:00:21,536:INFO:Initializing create_model()
2024-09-06 23:00:21,536:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000288D4363110>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000288D51F55D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-06 23:00:21,536:INFO:Checking exceptions
2024-09-06 23:00:21,536:INFO:Importing libraries
2024-09-06 23:00:21,536:INFO:Copying training dataset
2024-09-06 23:00:21,566:INFO:Defining folds
2024-09-06 23:00:21,566:INFO:Declaring metric variables
2024-09-06 23:00:21,572:INFO:Importing untrained model
2024-09-06 23:00:21,579:INFO:Linear Discriminant Analysis Imported successfully
2024-09-06 23:00:21,597:INFO:Starting cross validation
2024-09-06 23:00:21,600:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-06 23:00:22,026:INFO:Calculating mean and std
2024-09-06 23:00:22,030:INFO:Creating metrics dataframe
2024-09-06 23:00:22,033:INFO:Uploading results into container
2024-09-06 23:00:22,034:INFO:Uploading model into container now
2024-09-06 23:00:22,035:INFO:_master_model_container: 11
2024-09-06 23:00:22,035:INFO:_display_container: 2
2024-09-06 23:00:22,037:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-09-06 23:00:22,037:INFO:create_model() successfully completed......................................
2024-09-06 23:00:22,285:INFO:SubProcess create_model() end ==================================
2024-09-06 23:00:22,286:INFO:Creating metrics dataframe
2024-09-06 23:00:22,310:INFO:Initializing Extra Trees Classifier
2024-09-06 23:00:22,310:INFO:Total runtime is 0.6548537453015646 minutes
2024-09-06 23:00:22,317:INFO:SubProcess create_model() called ==================================
2024-09-06 23:00:22,318:INFO:Initializing create_model()
2024-09-06 23:00:22,318:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000288D4363110>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000288D51F55D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-06 23:00:22,318:INFO:Checking exceptions
2024-09-06 23:00:22,318:INFO:Importing libraries
2024-09-06 23:00:22,318:INFO:Copying training dataset
2024-09-06 23:00:22,358:INFO:Defining folds
2024-09-06 23:00:22,358:INFO:Declaring metric variables
2024-09-06 23:00:22,371:INFO:Importing untrained model
2024-09-06 23:00:22,383:INFO:Extra Trees Classifier Imported successfully
2024-09-06 23:00:22,408:INFO:Starting cross validation
2024-09-06 23:00:22,411:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-06 23:00:27,568:INFO:Calculating mean and std
2024-09-06 23:00:27,570:INFO:Creating metrics dataframe
2024-09-06 23:00:27,576:INFO:Uploading results into container
2024-09-06 23:00:27,581:INFO:Uploading model into container now
2024-09-06 23:00:27,584:INFO:_master_model_container: 12
2024-09-06 23:00:27,584:INFO:_display_container: 2
2024-09-06 23:00:27,585:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2024-09-06 23:00:27,585:INFO:create_model() successfully completed......................................
2024-09-06 23:00:27,865:INFO:SubProcess create_model() end ==================================
2024-09-06 23:00:27,866:INFO:Creating metrics dataframe
2024-09-06 23:00:27,890:INFO:Initializing Extreme Gradient Boosting
2024-09-06 23:00:27,890:INFO:Total runtime is 0.7478558977444967 minutes
2024-09-06 23:00:27,910:INFO:SubProcess create_model() called ==================================
2024-09-06 23:00:27,910:INFO:Initializing create_model()
2024-09-06 23:00:27,911:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000288D4363110>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000288D51F55D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-06 23:00:27,912:INFO:Checking exceptions
2024-09-06 23:00:27,912:INFO:Importing libraries
2024-09-06 23:00:27,912:INFO:Copying training dataset
2024-09-06 23:00:27,957:INFO:Defining folds
2024-09-06 23:00:27,958:INFO:Declaring metric variables
2024-09-06 23:00:27,972:INFO:Importing untrained model
2024-09-06 23:00:27,984:INFO:Extreme Gradient Boosting Imported successfully
2024-09-06 23:00:28,004:INFO:Starting cross validation
2024-09-06 23:00:28,009:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-06 23:00:29,888:INFO:Calculating mean and std
2024-09-06 23:00:29,892:INFO:Creating metrics dataframe
2024-09-06 23:00:29,896:INFO:Uploading results into container
2024-09-06 23:00:29,897:INFO:Uploading model into container now
2024-09-06 23:00:29,898:INFO:_master_model_container: 13
2024-09-06 23:00:29,899:INFO:_display_container: 2
2024-09-06 23:00:29,901:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-09-06 23:00:29,901:INFO:create_model() successfully completed......................................
2024-09-06 23:00:30,185:INFO:SubProcess create_model() end ==================================
2024-09-06 23:00:30,185:INFO:Creating metrics dataframe
2024-09-06 23:00:30,205:INFO:Initializing Light Gradient Boosting Machine
2024-09-06 23:00:30,205:INFO:Total runtime is 0.7864340782165528 minutes
2024-09-06 23:00:30,213:INFO:SubProcess create_model() called ==================================
2024-09-06 23:00:30,213:INFO:Initializing create_model()
2024-09-06 23:00:30,213:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000288D4363110>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000288D51F55D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-06 23:00:30,213:INFO:Checking exceptions
2024-09-06 23:00:30,214:INFO:Importing libraries
2024-09-06 23:00:30,214:INFO:Copying training dataset
2024-09-06 23:00:30,246:INFO:Defining folds
2024-09-06 23:00:30,247:INFO:Declaring metric variables
2024-09-06 23:00:30,260:INFO:Importing untrained model
2024-09-06 23:00:30,269:INFO:Light Gradient Boosting Machine Imported successfully
2024-09-06 23:00:30,285:INFO:Starting cross validation
2024-09-06 23:00:30,288:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-06 23:00:33,607:INFO:Calculating mean and std
2024-09-06 23:00:33,610:INFO:Creating metrics dataframe
2024-09-06 23:00:33,614:INFO:Uploading results into container
2024-09-06 23:00:33,615:INFO:Uploading model into container now
2024-09-06 23:00:33,617:INFO:_master_model_container: 14
2024-09-06 23:00:33,617:INFO:_display_container: 2
2024-09-06 23:00:33,618:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-09-06 23:00:33,620:INFO:create_model() successfully completed......................................
2024-09-06 23:00:33,875:INFO:SubProcess create_model() end ==================================
2024-09-06 23:00:33,875:INFO:Creating metrics dataframe
2024-09-06 23:00:33,888:INFO:Initializing CatBoost Classifier
2024-09-06 23:00:33,889:INFO:Total runtime is 0.8478336095809936 minutes
2024-09-06 23:00:33,895:INFO:SubProcess create_model() called ==================================
2024-09-06 23:00:33,896:INFO:Initializing create_model()
2024-09-06 23:00:33,896:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000288D4363110>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000288D51F55D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-06 23:00:33,896:INFO:Checking exceptions
2024-09-06 23:00:33,896:INFO:Importing libraries
2024-09-06 23:00:33,896:INFO:Copying training dataset
2024-09-06 23:00:33,922:INFO:Defining folds
2024-09-06 23:00:33,922:INFO:Declaring metric variables
2024-09-06 23:00:33,928:INFO:Importing untrained model
2024-09-06 23:00:33,933:INFO:CatBoost Classifier Imported successfully
2024-09-06 23:00:33,947:INFO:Starting cross validation
2024-09-06 23:00:33,950:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-06 23:01:35,512:INFO:Calculating mean and std
2024-09-06 23:01:35,518:INFO:Creating metrics dataframe
2024-09-06 23:01:35,523:INFO:Uploading results into container
2024-09-06 23:01:35,526:INFO:Uploading model into container now
2024-09-06 23:01:35,527:INFO:_master_model_container: 15
2024-09-06 23:01:35,527:INFO:_display_container: 2
2024-09-06 23:01:35,527:INFO:<catboost.core.CatBoostClassifier object at 0x00000288D4E330D0>
2024-09-06 23:01:35,527:INFO:create_model() successfully completed......................................
2024-09-06 23:01:35,830:INFO:SubProcess create_model() end ==================================
2024-09-06 23:01:35,830:INFO:Creating metrics dataframe
2024-09-06 23:01:35,860:INFO:Initializing Dummy Classifier
2024-09-06 23:01:35,861:INFO:Total runtime is 1.8807011008262635 minutes
2024-09-06 23:01:35,867:INFO:SubProcess create_model() called ==================================
2024-09-06 23:01:35,868:INFO:Initializing create_model()
2024-09-06 23:01:35,869:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000288D4363110>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000288D51F55D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-06 23:01:35,869:INFO:Checking exceptions
2024-09-06 23:01:35,870:INFO:Importing libraries
2024-09-06 23:01:35,870:INFO:Copying training dataset
2024-09-06 23:01:35,913:INFO:Defining folds
2024-09-06 23:01:35,913:INFO:Declaring metric variables
2024-09-06 23:01:35,926:INFO:Importing untrained model
2024-09-06 23:01:35,935:INFO:Dummy Classifier Imported successfully
2024-09-06 23:01:35,951:INFO:Starting cross validation
2024-09-06 23:01:35,955:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-06 23:01:36,217:WARNING:c:\Users\ardav\miniconda3\envs\vsc\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-06 23:01:36,227:WARNING:c:\Users\ardav\miniconda3\envs\vsc\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-06 23:01:36,247:WARNING:c:\Users\ardav\miniconda3\envs\vsc\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-06 23:01:36,256:WARNING:c:\Users\ardav\miniconda3\envs\vsc\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-06 23:01:36,273:WARNING:c:\Users\ardav\miniconda3\envs\vsc\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-06 23:01:36,297:WARNING:c:\Users\ardav\miniconda3\envs\vsc\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-06 23:01:36,302:WARNING:c:\Users\ardav\miniconda3\envs\vsc\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-06 23:01:36,318:WARNING:c:\Users\ardav\miniconda3\envs\vsc\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-06 23:01:36,339:WARNING:c:\Users\ardav\miniconda3\envs\vsc\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-06 23:01:36,342:WARNING:c:\Users\ardav\miniconda3\envs\vsc\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-09-06 23:01:36,356:INFO:Calculating mean and std
2024-09-06 23:01:36,360:INFO:Creating metrics dataframe
2024-09-06 23:01:36,368:INFO:Uploading results into container
2024-09-06 23:01:36,370:INFO:Uploading model into container now
2024-09-06 23:01:36,371:INFO:_master_model_container: 16
2024-09-06 23:01:36,371:INFO:_display_container: 2
2024-09-06 23:01:36,372:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2024-09-06 23:01:36,372:INFO:create_model() successfully completed......................................
2024-09-06 23:01:36,683:INFO:SubProcess create_model() end ==================================
2024-09-06 23:01:36,683:INFO:Creating metrics dataframe
2024-09-06 23:01:36,745:INFO:Initializing create_model()
2024-09-06 23:01:36,746:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000288D4363110>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-06 23:01:36,746:INFO:Checking exceptions
2024-09-06 23:01:36,751:INFO:Importing libraries
2024-09-06 23:01:36,752:INFO:Copying training dataset
2024-09-06 23:01:36,791:INFO:Defining folds
2024-09-06 23:01:36,791:INFO:Declaring metric variables
2024-09-06 23:01:36,792:INFO:Importing untrained model
2024-09-06 23:01:36,792:INFO:Declaring custom model
2024-09-06 23:01:36,793:INFO:Light Gradient Boosting Machine Imported successfully
2024-09-06 23:01:36,796:INFO:Cross validation set to False
2024-09-06 23:01:36,796:INFO:Fitting Model
2024-09-06 23:01:37,055:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-09-06 23:01:37,056:INFO:[LightGBM] [Info] Number of positive: 13834, number of negative: 13834
2024-09-06 23:01:37,066:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002353 seconds.
2024-09-06 23:01:37,066:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-09-06 23:01:37,066:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-09-06 23:01:37,067:INFO:[LightGBM] [Info] Total Bins 3808
2024-09-06 23:01:37,067:INFO:[LightGBM] [Info] Number of data points in the train set: 27668, number of used features: 15
2024-09-06 23:01:37,067:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-09-06 23:01:37,508:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-09-06 23:01:37,508:INFO:create_model() successfully completed......................................
2024-09-06 23:01:37,849:INFO:_master_model_container: 16
2024-09-06 23:01:37,849:INFO:_display_container: 2
2024-09-06 23:01:37,851:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-09-06 23:01:37,851:INFO:compare_models() successfully completed......................................
2024-09-06 23:01:37,853:INFO:Initializing tune_model()
2024-09-06 23:01:37,853:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000288D4363110>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=F1, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2024-09-06 23:01:37,853:INFO:Checking exceptions
2024-09-06 23:01:37,898:INFO:Copying training dataset
2024-09-06 23:01:37,919:INFO:Checking base model
2024-09-06 23:01:37,920:INFO:Base model : Light Gradient Boosting Machine
2024-09-06 23:01:37,931:INFO:Declaring metric variables
2024-09-06 23:01:37,941:INFO:Defining Hyperparameters
2024-09-06 23:01:38,234:INFO:Tuning with n_jobs=-1
2024-09-06 23:01:38,234:INFO:Initializing RandomizedSearchCV
2024-09-06 23:02:25,411:INFO:best_params: {'actual_estimator__reg_lambda': 3, 'actual_estimator__reg_alpha': 2, 'actual_estimator__num_leaves': 70, 'actual_estimator__n_estimators': 260, 'actual_estimator__min_split_gain': 0.9, 'actual_estimator__min_child_samples': 41, 'actual_estimator__learning_rate': 0.1, 'actual_estimator__feature_fraction': 0.4, 'actual_estimator__bagging_freq': 2, 'actual_estimator__bagging_fraction': 0.6}
2024-09-06 23:02:25,413:INFO:Hyperparameter search completed
2024-09-06 23:02:25,413:INFO:SubProcess create_model() called ==================================
2024-09-06 23:02:25,416:INFO:Initializing create_model()
2024-09-06 23:02:25,417:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000288D4363110>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000288D4E40F90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 3, 'reg_alpha': 2, 'num_leaves': 70, 'n_estimators': 260, 'min_split_gain': 0.9, 'min_child_samples': 41, 'learning_rate': 0.1, 'feature_fraction': 0.4, 'bagging_freq': 2, 'bagging_fraction': 0.6})
2024-09-06 23:02:25,417:INFO:Checking exceptions
2024-09-06 23:02:25,417:INFO:Importing libraries
2024-09-06 23:02:25,417:INFO:Copying training dataset
2024-09-06 23:02:25,452:INFO:Defining folds
2024-09-06 23:02:25,452:INFO:Declaring metric variables
2024-09-06 23:02:25,459:INFO:Importing untrained model
2024-09-06 23:02:25,459:INFO:Declaring custom model
2024-09-06 23:02:25,467:INFO:Light Gradient Boosting Machine Imported successfully
2024-09-06 23:02:25,480:INFO:Starting cross validation
2024-09-06 23:02:25,482:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-06 23:02:29,138:INFO:Calculating mean and std
2024-09-06 23:02:29,140:INFO:Creating metrics dataframe
2024-09-06 23:02:29,152:INFO:Finalizing model
2024-09-06 23:02:29,317:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-09-06 23:02:29,317:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-09-06 23:02:29,317:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-09-06 23:02:29,343:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-09-06 23:02:29,343:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-09-06 23:02:29,344:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-09-06 23:02:29,344:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-09-06 23:02:29,344:INFO:[LightGBM] [Info] Number of positive: 13834, number of negative: 13834
2024-09-06 23:02:29,348:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002758 seconds.
2024-09-06 23:02:29,349:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-09-06 23:02:29,349:INFO:[LightGBM] [Info] Total Bins 3808
2024-09-06 23:02:29,349:INFO:[LightGBM] [Info] Number of data points in the train set: 27668, number of used features: 15
2024-09-06 23:02:29,351:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-09-06 23:02:29,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:29,373:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:29,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:29,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:29,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:29,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:29,399:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:29,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:29,410:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:29,419:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:29,425:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:29,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:29,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:29,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:29,446:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:29,451:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:29,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:29,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:29,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:29,473:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:29,479:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:29,483:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:29,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:29,520:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:29,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:29,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:29,588:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:29,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:29,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:29,653:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:29,680:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:29,695:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:29,700:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:29,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:29,707:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:29,712:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:29,715:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:29,719:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:29,722:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:29,727:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:29,730:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:29,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:29,738:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:29,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:29,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:29,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:29,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:29,756:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:29,759:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:29,763:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:29,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:29,769:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:29,774:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:29,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:29,782:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:29,785:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:29,789:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:29,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:29,793:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:29,796:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:29,799:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:29,803:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:29,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:29,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:29,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:29,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:29,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:29,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:29,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:29,829:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:29,830:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:29,834:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:29,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:29,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:29,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:29,845:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:29,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:29,850:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:29,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:29,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:29,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:29,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:29,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:29,863:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:29,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:29,868:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:29,870:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:29,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:29,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:29,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:29,881:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:29,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:29,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:29,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:29,892:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:29,894:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:29,896:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:29,899:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:29,901:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:29,904:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:29,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:29,908:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:29,911:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:29,914:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:29,916:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:29,919:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:29,921:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:29,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:29,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:29,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:29,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:29,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:29,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:29,935:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-09-06 23:02:29,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:29,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:29,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:29,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:29,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:29,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:29,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:29,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:29,952:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:29,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:29,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:29,958:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:29,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:29,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:29,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:29,963:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:29,966:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:29,968:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:29,970:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:29,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:29,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:29,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:29,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:29,979:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:29,982:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:29,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:29,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:29,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:29,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:29,988:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-09-06 23:02:29,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:29,991:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:29,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:29,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:29,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:29,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:29,999:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:30,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:30,002:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:30,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:30,005:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:30,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:30,009:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:30,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:30,011:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:30,014:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:30,015:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:30,016:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:30,016:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-09-06 23:02:30,018:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:30,020:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:30,022:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:30,024:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:30,026:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:30,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:30,030:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:30,032:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:30,033:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:30,035:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:30,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:30,039:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:30,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:30,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:30,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:30,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:30,048:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:30,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:30,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:30,052:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:30,054:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:30,055:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:30,057:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:30,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:30,059:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:30,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:30,062:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:30,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:30,068:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:30,070:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:30,072:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:30,072:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-09-06 23:02:30,074:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:30,076:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:30,078:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:30,080:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:30,081:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:30,084:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:30,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:30,085:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-09-06 23:02:30,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:30,087:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:30,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:30,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:30,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:30,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:30,093:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-09-06 23:02:30,093:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:30,095:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:30,096:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:30,098:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:30,100:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:30,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:30,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:30,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:30,107:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:30,109:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:30,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:30,111:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:30,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:30,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:30,114:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-09-06 23:02:30,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:30,117:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:30,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:30,118:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-09-06 23:02:30,120:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:30,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:30,122:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:30,123:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:30,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:30,125:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:30,126:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:30,128:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:30,129:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:30,131:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:30,133:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:30,134:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:30,136:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:30,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:30,139:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:30,140:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:30,140:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-09-06 23:02:30,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:30,143:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:30,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:30,145:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:30,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:30,148:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:30,149:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:30,149:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-09-06 23:02:30,150:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:30,151:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:30,152:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:30,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:30,155:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:30,156:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:30,156:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-09-06 23:02:30,157:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:30,158:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:30,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:30,162:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:30,164:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:30,165:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:30,166:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-09-06 23:02:30,167:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-09-06 23:02:30,192:INFO:Uploading results into container
2024-09-06 23:02:30,193:INFO:Uploading model into container now
2024-09-06 23:02:30,194:INFO:_master_model_container: 17
2024-09-06 23:02:30,196:INFO:_display_container: 3
2024-09-06 23:02:30,197:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-09-06 23:02:30,197:INFO:create_model() successfully completed......................................
2024-09-06 23:02:30,428:INFO:SubProcess create_model() end ==================================
2024-09-06 23:02:30,429:INFO:choose_better activated
2024-09-06 23:02:30,434:INFO:SubProcess create_model() called ==================================
2024-09-06 23:02:30,435:INFO:Initializing create_model()
2024-09-06 23:02:30,435:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000288D4363110>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-09-06 23:02:30,435:INFO:Checking exceptions
2024-09-06 23:02:30,438:INFO:Importing libraries
2024-09-06 23:02:30,438:INFO:Copying training dataset
2024-09-06 23:02:30,454:INFO:Defining folds
2024-09-06 23:02:30,454:INFO:Declaring metric variables
2024-09-06 23:02:30,454:INFO:Importing untrained model
2024-09-06 23:02:30,454:INFO:Declaring custom model
2024-09-06 23:02:30,455:INFO:Light Gradient Boosting Machine Imported successfully
2024-09-06 23:02:30,455:INFO:Starting cross validation
2024-09-06 23:02:30,457:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-09-06 23:02:33,282:INFO:Calculating mean and std
2024-09-06 23:02:33,282:INFO:Creating metrics dataframe
2024-09-06 23:02:33,285:INFO:Finalizing model
2024-09-06 23:02:33,479:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-09-06 23:02:33,480:INFO:[LightGBM] [Info] Number of positive: 13834, number of negative: 13834
2024-09-06 23:02:33,487:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002183 seconds.
2024-09-06 23:02:33,487:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-09-06 23:02:33,487:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-09-06 23:02:33,487:INFO:[LightGBM] [Info] Total Bins 3808
2024-09-06 23:02:33,487:INFO:[LightGBM] [Info] Number of data points in the train set: 27668, number of used features: 15
2024-09-06 23:02:33,488:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-09-06 23:02:33,860:INFO:Uploading results into container
2024-09-06 23:02:33,861:INFO:Uploading model into container now
2024-09-06 23:02:33,862:INFO:_master_model_container: 18
2024-09-06 23:02:33,862:INFO:_display_container: 4
2024-09-06 23:02:33,862:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-09-06 23:02:33,862:INFO:create_model() successfully completed......................................
2024-09-06 23:02:34,113:INFO:SubProcess create_model() end ==================================
2024-09-06 23:02:34,114:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for F1 is 0.7056
2024-09-06 23:02:34,115:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for F1 is 0.6982
2024-09-06 23:02:34,115:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2024-09-06 23:02:34,115:INFO:choose_better completed
2024-09-06 23:02:34,115:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2024-09-06 23:02:34,127:INFO:_master_model_container: 18
2024-09-06 23:02:34,127:INFO:_display_container: 3
2024-09-06 23:02:34,128:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-09-06 23:02:34,128:INFO:tune_model() successfully completed......................................
2024-09-06 23:02:34,336:INFO:Initializing finalize_model()
2024-09-06 23:02:34,337:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000288D4363110>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-09-06 23:02:34,337:INFO:Finalizing LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-09-06 23:02:34,347:INFO:Initializing create_model()
2024-09-06 23:02:34,347:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000288D4363110>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-09-06 23:02:34,347:INFO:Checking exceptions
2024-09-06 23:02:34,348:INFO:Importing libraries
2024-09-06 23:02:34,348:INFO:Copying training dataset
2024-09-06 23:02:34,350:INFO:Defining folds
2024-09-06 23:02:34,350:INFO:Declaring metric variables
2024-09-06 23:02:34,350:INFO:Importing untrained model
2024-09-06 23:02:34,351:INFO:Declaring custom model
2024-09-06 23:02:34,351:INFO:Light Gradient Boosting Machine Imported successfully
2024-09-06 23:02:34,352:INFO:Cross validation set to False
2024-09-06 23:02:34,353:INFO:Fitting Model
2024-09-06 23:02:34,528:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-09-06 23:02:34,529:INFO:[LightGBM] [Info] Number of positive: 19763, number of negative: 19763
2024-09-06 23:02:34,533:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001274 seconds.
2024-09-06 23:02:34,534:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-09-06 23:02:34,534:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-09-06 23:02:34,534:INFO:[LightGBM] [Info] Total Bins 3807
2024-09-06 23:02:34,534:INFO:[LightGBM] [Info] Number of data points in the train set: 39526, number of used features: 15
2024-09-06 23:02:34,534:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-09-06 23:02:34,805:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Tahun Kelahiran',
                                             'Kelas Pekerjaan', 'fnlwgt',
                                             'Pendidikan', 'Jenjang Pendidikan',
                                             'Status', 'Pekerjaan', 'Hubungan',
                                             'Etnis', 'sex', 'pendapatan',
                                             'pengeluaran', 'hours per week',
                                             'Asal Negara', 'jumlah_anak'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-09-06 23:02:34,805:INFO:create_model() successfully completed......................................
2024-09-06 23:02:35,043:INFO:_master_model_container: 18
2024-09-06 23:02:35,043:INFO:_display_container: 3
2024-09-06 23:02:35,051:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Tahun Kelahiran',
                                             'Kelas Pekerjaan', 'fnlwgt',
                                             'Pendidikan', 'Jenjang Pendidikan',
                                             'Status', 'Pekerjaan', 'Hubungan',
                                             'Etnis', 'sex', 'pendapatan',
                                             'pengeluaran', 'hours per week',
                                             'Asal Negara', 'jumlah_anak'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-09-06 23:02:35,051:INFO:finalize_model() successfully completed......................................
2024-09-06 23:02:35,302:INFO:Initializing predict_model()
2024-09-06 23:02:35,303:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000288D4363110>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Tahun Kelahiran',
                                             'Kelas Pekerjaan', 'fnlwgt',
                                             'Pendidikan', 'Jenjang Pendidikan',
                                             'Status', 'Pekerjaan', 'Hubungan',
                                             'Etnis', 'sex', 'pendapatan',
                                             'pengeluaran', 'hours per week',
                                             'Asal Negara', 'jumlah_anak'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000288D5006480>)
2024-09-06 23:02:35,303:INFO:Checking exceptions
2024-09-06 23:02:35,303:INFO:Preloading libraries
2024-09-06 23:02:35,307:INFO:Set up data.
2024-09-06 23:02:35,322:INFO:Set up index.
